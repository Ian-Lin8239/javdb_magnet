"""
JavDB ç£åŠ›éˆæ¥å°ˆç”¨çˆ¬èŸ²
å°ˆé–€ç”¨æ–¼ç²å–æœ‰ç¢¼æœˆæ¦œå‰30çš„ç£åŠ›éˆæ¥ä¸‹è¼‰ä½ç½®
"""
import requests
import time
import random
import re
import os
from typing import List, Optional, Dict, Any
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from datetime import datetime
from utils import (
    get_random_user_agent, random_delay, clean_text, setup_logging
)
from duplicate_tracker import DuplicateTracker

class MagnetLink:
    """ç£åŠ›éˆæ¥æ•¸æ“šæ¨¡å‹"""
    def __init__(self):
        self.title = ""  # ç£åŠ›éˆæ¥æ¨™é¡Œ
        self.size = ""  # æ–‡ä»¶å¤§å°
        self.file_count = 0  # æ–‡ä»¶æ•¸é‡
        self.tags = []  # æ¨™ç±¤ (é«˜æ¸…, å­—å¹•ç­‰)
        self.magnet_url = ""  # ç£åŠ›éˆæ¥URL
        self.copy_url = ""  # è¤‡è£½æŒ‰éˆ•çš„å¯¦éš›ä¸‹è¼‰éˆæ¥
        self.download_url = ""  # ä¸‹è¼‰æŒ‰éˆ•çš„éˆæ¥
        self.date = ""  # ä¸Šå‚³æ—¥æœŸ
        self.quality = ""  # è³ªé‡æ¨™è­˜

class JavDBMagnetCrawler:
    """JavDB ç£åŠ›éˆæ¥å°ˆç”¨çˆ¬èŸ²"""
    
    def __init__(self):
        self.base_url = "https://javdb.com"
        self.session = requests.Session()
        self.logger = setup_logging()
        self._setup_session()
    
    def _setup_session(self):
        """è¨­ç½®æœƒè©±"""
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,ja;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0",
            "DNT": "1",
            "Sec-GPC": "1"
        })
    
    def _make_request(self, url: str, params: Optional[Dict] = None, 
                     retries: int = 3) -> Optional[requests.Response]:
        """ç™¼é€HTTPè«‹æ±‚"""
        for attempt in range(retries + 1):
            try:
                # éš¨æ©Ÿå»¶é²
                if attempt > 0:
                    random_delay(2, 5)
                
                # æ›´æ–°User-Agent
                self.session.headers['User-Agent'] = get_random_user_agent()
                
                response = self.session.get(
                    url, 
                    params=params, 
                    timeout=30,
                    allow_redirects=True,
                    headers={'Accept-Encoding': 'gzip, deflate'}
                )
                
                response.raise_for_status()
                
                # è«‹æ±‚é–“éš”
                random_delay(1, 3)
                
                return response
                
            except requests.RequestException as e:
                self.logger.warning(f"è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt + 1}/{retries + 1}): {e}")
                
                if attempt == retries:
                    self.logger.error(f"è«‹æ±‚æœ€çµ‚å¤±æ•—: {url}")
                    return None
                
                # æŒ‡æ•¸é€€é¿
                time.sleep(2 ** attempt)
        
        return None
    
    def get_monthly_rankings_with_magnets(self, limit: int = 30) -> List[Dict[str, Any]]:
        """ç²å–æœ‰ç¢¼æœˆæ¦œå‰30çš„å½±ç‰‡åŠå…¶ç£åŠ›éˆæ¥"""
        self.logger.info(f"é–‹å§‹ç²å–æœ‰ç¢¼æœˆæ¦œå‰{limit}çš„å½±ç‰‡ç£åŠ›éˆæ¥")
        
        # 1. ç²å–æ’è¡Œæ¦œé é¢
        rankings_url = f"{self.base_url}/rankings/movies"
        params = {
            "p": "monthly",  # æœˆæ¦œ
            "t": "censored",  # æœ‰ç¢¼
            "page": 1
        }
        
        response = self._make_request(rankings_url, params)
        if not response:
            self.logger.error("ç„¡æ³•ç²å–æ’è¡Œæ¦œé é¢")
            return []
        
        # 2. è§£ææ’è¡Œæ¦œï¼Œç²å–å½±ç‰‡åˆ—è¡¨
        movies = self._parse_rankings_page(response.text, limit)
        self.logger.info(f"å¾æ’è¡Œæ¦œç²å–åˆ° {len(movies)} éƒ¨å½±ç‰‡")
        
        # 3. å‰µå»ºå³æ™‚å¯«å…¥æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"magnet/javdb_monthly_magnets_{timestamp}.txt"
        os.makedirs("magnet", exist_ok=True)
        
        # 4. ç‚ºæ¯éƒ¨å½±ç‰‡ç²å–ç£åŠ›éˆæ¥ä¸¦å³æ™‚å¯«å…¥
        results = []
        with open(filename, 'w', encoding='utf-8') as f:
            # å¯«å…¥æ–‡ä»¶é ­
            f.write("JavDB æœ‰ç¢¼æœˆæ¦œå‰30ç£åŠ›éˆæ¥\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n\n")
            f.write("ç£åŠ›éˆæ¥åˆ—è¡¨ï¼ˆå³æ™‚æ›´æ–°ï¼‰\n")
            f.write("=" * 80 + "\n\n")
            f.flush()  # å¼·åˆ¶å¯«å…¥
            
            for i, movie in enumerate(movies, 1):
                self.logger.info(f"è™•ç†ç¬¬ {i}/{len(movies)} éƒ¨å½±ç‰‡: {movie['title']}")
                
                # ç²å–ç£åŠ›éˆæ¥
                magnet_links = self.get_movie_magnet_links(movie['detail_url'])
                
                # æ ¹æ“šå„ªå…ˆé †åºéæ¿¾ç£åŠ›éˆæ¥
                filtered_magnets = self._filter_magnets_by_priority(magnet_links)
                
                result = {
                    'rank': i,
                    'movie': movie,
                    'magnet_links': filtered_magnets,
                    'total_magnets': len(magnet_links),
                    'filtered_magnets': len(filtered_magnets)
                }
                
                # å˜—è©¦å¾ç£åŠ›éˆæ¥ä¸­æå–çœŸå¯¦ç•ªè™Ÿ
                if filtered_magnets and (not movie['code'] or len(movie['code']) < 5):
                    magnet = filtered_magnets[0]
                    real_code = self._extract_real_code_from_magnet(magnet.copy_url or magnet.magnet_url)
                    if real_code:
                        movie['code'] = real_code
                
                results.append(result)
                
                # å³æ™‚å¯«å…¥åˆ°æ–‡ä»¶
                f.write(f"æ’å: {i}\n")
                f.write(f"ç•ªè™Ÿ: {movie['code']}\n")
                f.write(f"æ¨™é¡Œ: {movie['title']}\n")
                f.write(f"æ¼”å“¡: {', '.join(movie['actors'])}\n")
                f.write(f"è©•åˆ†: {movie['score']}\n")
                f.write(f"ç¸½ç£åŠ›éˆæ¥: {len(magnet_links)} å€‹\n")
                f.write(f"é¸æ“‡ç£åŠ›éˆæ¥: {len(filtered_magnets)} å€‹\n")
                
                if filtered_magnets:
                    magnet = filtered_magnets[0]  # åªå–ç¬¬ä¸€å€‹ï¼ˆæœ€ä½³é¸æ“‡ï¼‰
                    f.write(f"ç£åŠ›éˆæ¥: {magnet.copy_url or magnet.magnet_url}\n")
                    f.write(f"å¤§å°: {magnet.size}\n")
                    f.write(f"æ¨™ç±¤: {', '.join(magnet.tags)}\n")
                    f.write(f"æ—¥æœŸ: {magnet.date}\n")
                else:
                    f.write("ç„¡ç¬¦åˆæ¢ä»¶çš„ç£åŠ›éˆæ¥\n")
                
                f.write("-" * 80 + "\n\n")
                f.flush()  # å¼·åˆ¶å¯«å…¥ï¼Œç¢ºä¿å³æ™‚ä¿å­˜
                
                # é¿å…è«‹æ±‚éæ–¼é »ç¹
                random_delay(2, 4)
            
            # å¯«å…¥çµ±è¨ˆä¿¡æ¯
            total_magnets = sum(result['total_magnets'] for result in results)
            filtered_magnets = sum(result['filtered_magnets'] for result in results)
            
            f.write("=" * 80 + "\n")
            f.write("çµ±è¨ˆä¿¡æ¯\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç¸½å½±ç‰‡æ•¸: {len(results)}\n")
            f.write(f"ç¸½ç£åŠ›éˆæ¥æ•¸: {total_magnets}\n")
            f.write(f"é¸æ“‡ç£åŠ›éˆæ¥æ•¸: {filtered_magnets}\n")
            f.write(f"æˆåŠŸç‡: {filtered_magnets/total_magnets*100:.1f}%\n")
            f.write(f"å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        self.logger.info(f"ç£åŠ›éˆæ¥å·²å³æ™‚ä¿å­˜åˆ°: {filename}")
        return results
    
    def _parse_rankings_page(self, html_content: str, limit: int) -> List[Dict[str, Any]]:
        """è§£ææ’è¡Œæ¦œé é¢"""
        soup = BeautifulSoup(html_content, 'html.parser')
        movies = []
        
        # èª¿è©¦ï¼šæª¢æŸ¥é é¢å…§å®¹
        self.logger.info(f"é é¢å…§å®¹é•·åº¦: {len(html_content)}")
        
        # æŸ¥æ‰¾é›»å½±åˆ—è¡¨å®¹å™¨
        movie_items = soup.find_all('div', class_='item')
        self.logger.info(f"æ‰¾åˆ° {len(movie_items)} å€‹é›»å½±é …ç›®")
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦å…¶ä»–é¸æ“‡å™¨
        if not movie_items:
            movie_items = soup.find_all('div', class_='movie-item')
            self.logger.info(f"ä½¿ç”¨ movie-item æ‰¾åˆ° {len(movie_items)} å€‹é …ç›®")
        
        if not movie_items:
            movie_items = soup.find_all('div', class_='video-item')
            self.logger.info(f"ä½¿ç”¨ video-item æ‰¾åˆ° {len(movie_items)} å€‹é …ç›®")
        
        # èª¿è©¦ï¼šä¿å­˜é é¢å…§å®¹
        with open('debug_page.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
        self.logger.info("å·²ä¿å­˜èª¿è©¦é é¢åˆ° debug_page.html")
        
        for index, item in enumerate(movie_items[:limit]):
            try:
                movie = self._parse_movie_item(item, index + 1)
                if movie:
                    movies.append(movie)
            except Exception as e:
                self.logger.warning(f"è§£æé›»å½±é …ç›®å¤±æ•—: {e}")
                continue
        
        return movies
    
    def _parse_movie_item(self, item, rank: int) -> Optional[Dict[str, Any]]:
        """è§£æé›»å½±é …ç›®"""
        movie = {
            'rank': rank,
            'code': '',
            'title': '',
            'detail_url': '',
            'cover_url': '',
            'score': 0.0,
            'actors': [],
            'tags': []
        }
        
        # ç²å–é›»å½±éˆæ¥
        link_elem = item.find('a')
        if not link_elem:
            return None
        
        movie['detail_url'] = urljoin(self.base_url, link_elem.get('href', ''))
        
        # å¾URLæå–ç•ªè™Ÿï¼ˆé€™æ˜¯JavDBçš„çŸ­ä»£ç¢¼ï¼Œä¸æ˜¯çœŸå¯¦ç•ªè™Ÿï¼‰
        url_parts = movie['detail_url'].split('/')
        if len(url_parts) > 1:
            movie['code'] = url_parts[-1]  # çŸ­ä»£ç¢¼ï¼Œå¾ŒçºŒæœƒå˜—è©¦å¾ç£åŠ›éˆæ¥æå–çœŸå¯¦ç•ªè™Ÿ
        
        # ç²å–å°é¢åœ–ç‰‡
        img_elem = item.find('img')
        if img_elem:
            movie['cover_url'] = urljoin(self.base_url, img_elem.get('src', ''))
        
        # ç²å–æ¨™é¡Œ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        title_elem = item.find('div', class_='video-title')
        if not title_elem:
            title_elem = item.find('div', class_='title')
        if not title_elem:
            title_elem = item.find('strong')
        if not title_elem:
            # å˜—è©¦å¾éˆæ¥æ–‡æœ¬ç²å–
            title_elem = link_elem
        
        if title_elem:
            if title_elem.name == 'a':
                title_text = title_elem.get('title', '') or title_elem.get_text()
            else:
                title_link = title_elem.find('a')
                if title_link:
                    title_text = title_link.get('title', '') or title_link.get_text()
                else:
                    title_text = title_elem.get_text()
            
            if title_text:
                movie['title'] = clean_text(title_text)
        
        # ç²å–è©•åˆ† - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        score_elem = item.find('span', class_='score')
        if not score_elem:
            score_elem = item.find('span', class_='rating')
        if not score_elem:
            score_elem = item.find('div', class_='score')
        if not score_elem:
            score_elem = item.find('span', class_='value')
        if score_elem:
            try:
                score_text = score_elem.get_text().strip()
                # ç§»é™¤å¯èƒ½çš„éæ•¸å­—å­—ç¬¦ï¼Œåªä¿ç•™æ•¸å­—å’Œå°æ•¸é»
                score_text = re.sub(r'[^\d.]', '', score_text)
                if score_text:
                    movie['score'] = float(score_text)
            except (ValueError, AttributeError):
                pass
        
        # ç²å–æ¨™ç±¤
        tags_elem = item.find('div', class_='tags')
        if not tags_elem:
            tags_elem = item.find('div', class_='tag-list')
        if tags_elem:
            tag_links = tags_elem.find_all('a')
            movie['tags'] = [clean_text(tag.get_text()) for tag in tag_links]
        
        # ç²å–æ¼”å“¡ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        actors_elem = item.find('div', class_='actors')
        if not actors_elem:
            actors_elem = item.find('div', class_='actor-list')
        if not actors_elem:
            actors_elem = item.find('div', class_='performers')
        if not actors_elem:
            # å˜—è©¦æŸ¥æ‰¾åŒ…å«"æ¼”å“¡"æˆ–"ä¸»æ¼”"æ–‡å­—çš„div
            for div in item.find_all('div'):
                div_text = div.get_text()
                if 'æ¼”å“¡' in div_text or 'ä¸»æ¼”' in div_text:
                    actors_elem = div
                    break
        
        if actors_elem:
            actor_links = actors_elem.find_all('a')
            if actor_links:
                movie['actors'] = [clean_text(actor.get_text()) for actor in actor_links]
            else:
                # å¦‚æœæ²’æœ‰éˆæ¥ï¼Œå˜—è©¦ç›´æ¥ç²å–æ–‡æœ¬ä¸¦åˆ†å‰²
                actor_text = actors_elem.get_text().strip()
                if actor_text:
                    # ç§»é™¤"æ¼”å“¡ï¼š"ç­‰å‰ç¶´
                    actor_text = re.sub(r'^[æ¼”å“¡ä¸»æ¼”ï¼š:]+', '', actor_text)
                    if actor_text:
                        movie['actors'] = [clean_text(a.strip()) for a in actor_text.split(',') if a.strip()]
        
        return movie
    
    def get_movie_magnet_links(self, movie_url: str) -> List[MagnetLink]:
        """ç²å–å½±ç‰‡çš„ç£åŠ›éˆæ¥"""
        self.logger.info(f"ç²å–ç£åŠ›éˆæ¥: {movie_url}")
        
        response = self._make_request(movie_url)
        if not response:
            self.logger.error(f"ç„¡æ³•ç²å–å½±ç‰‡è©³æƒ…é é¢: {movie_url}")
            return []
        
        return self._parse_magnet_links_page(response.text, movie_url)
    
    def _parse_magnet_links_page(self, html_content: str, movie_url: str) -> List[MagnetLink]:
        """è§£æç£åŠ›éˆæ¥é é¢"""
        soup = BeautifulSoup(html_content, 'html.parser')
        magnet_links = []
        
        # èª¿è©¦ï¼šä¿å­˜é é¢å…§å®¹
        with open('magnet_debug.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
        self.logger.info("å·²ä¿å­˜ç£åŠ›éˆæ¥é é¢åˆ° magnet_debug.html")
        
        # æŸ¥æ‰¾ç£åŠ›éˆæ¥å€åŸŸ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        magnet_section = None
        
        # å˜—è©¦ä¸åŒçš„é¸æ“‡å™¨
        selectors = [
            'div.magnet-links',
            'div#magnet-links', 
            'div.links',
            'div.magnet-list',
            'div.torrent-list',
            'div[class*="magnet"]',
            'div[class*="torrent"]'
        ]
        
        for selector in selectors:
            magnet_section = soup.select_one(selector)
            if magnet_section:
                self.logger.info(f"æ‰¾åˆ°ç£åŠ›éˆæ¥å€åŸŸ: {selector}")
                break
        
        if not magnet_section:
            # å¦‚æœæ‰¾ä¸åˆ°å°ˆé–€çš„ç£åŠ›éˆæ¥å€åŸŸï¼ŒæŸ¥æ‰¾åŒ…å«"è¤‡è£½"æŒ‰éˆ•çš„å€åŸŸ
            copy_buttons = soup.find_all('a', string='è¤‡è£½')
            if copy_buttons:
                self.logger.info(f"æ‰¾åˆ° {len(copy_buttons)} å€‹è¤‡è£½æŒ‰éˆ•")
                # å¾è¤‡è£½æŒ‰éˆ•å‘ä¸ŠæŸ¥æ‰¾çˆ¶å®¹å™¨
                for button in copy_buttons:
                    parent = button.find_parent('div') or button.find_parent('tr')
                    if parent:
                        magnet_link = self._parse_magnet_item(parent)
                        if magnet_link:
                            magnet_links.append(magnet_link)
                return magnet_links
            else:
                self.logger.warning("æœªæ‰¾åˆ°ç£åŠ›éˆæ¥å€åŸŸå’Œè¤‡è£½æŒ‰éˆ•")
                return []
        
        # æŸ¥æ‰¾ç£åŠ›éˆæ¥é …ç›®
        magnet_items = []
        
        # å˜—è©¦ä¸åŒçš„é …ç›®é¸æ“‡å™¨
        item_selectors = [
            'div.magnet-item',
            'div.link-item', 
            'tr',
            'div[class*="item"]',
            'div[class*="link"]'
        ]
        
        for selector in item_selectors:
            items = magnet_section.select(selector)
            if items:
                magnet_items = items
                self.logger.info(f"ä½¿ç”¨é¸æ“‡å™¨ {selector} æ‰¾åˆ° {len(items)} å€‹é …ç›®")
                break
        
        if not magnet_items:
            # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼ŒæŸ¥æ‰¾æ‰€æœ‰åŒ…å«"è¤‡è£½"æˆ–"ä¸‹è¼‰"æŒ‰éˆ•çš„div
            magnet_items = magnet_section.find_all('div', string=lambda text: text and ('è¤‡è£½' in text or 'ä¸‹è¼‰' in text))
            if not magnet_items:
                magnet_items = magnet_section.find_all('div')
        
        self.logger.info(f"é–‹å§‹è§£æ {len(magnet_items)} å€‹ç£åŠ›éˆæ¥é …ç›®")
        
        for i, item in enumerate(magnet_items):
            try:
                magnet_link = self._parse_magnet_item(item)
                if magnet_link:
                    magnet_links.append(magnet_link)
                    self.logger.info(f"æˆåŠŸè§£æç¬¬ {i+1} å€‹ç£åŠ›éˆæ¥: {magnet_link.title}")
                else:
                    self.logger.debug(f"ç¬¬ {i+1} å€‹é …ç›®è§£æå¤±æ•—")
            except Exception as e:
                self.logger.warning(f"è§£æç£åŠ›éˆæ¥é …ç›®å¤±æ•—: {e}")
                continue
        
        self.logger.info(f"ç¸½å…±è§£æå‡º {len(magnet_links)} å€‹ç£åŠ›éˆæ¥")
        return magnet_links
    
    def _parse_magnet_item(self, item) -> Optional[MagnetLink]:
        """è§£æç£åŠ›éˆæ¥é …ç›®"""
        magnet = MagnetLink()
        
        # ç²å–æ¨™é¡Œï¼ˆé€šå¸¸æ˜¯ç•ªè™Ÿï¼‰
        title_elem = item.find('span', class_='title') or item.find('td', class_='title') or item.find('strong')
        if title_elem:
            magnet.title = clean_text(title_elem.get_text())
        
        # ç²å–å¤§å°å’Œæ–‡ä»¶æ•¸é‡
        size_elem = item.find('span', class_='size') or item.find('td', class_='size')
        if size_elem:
            size_text = clean_text(size_elem.get_text())
            magnet.size = size_text
            
            # è§£ææ–‡ä»¶æ•¸é‡
            file_count_match = re.search(r'(\d+)å€‹æ–‡ä»¶', size_text)
            if file_count_match:
                magnet.file_count = int(file_count_match.group(1))
        
        # ç²å–æ¨™ç±¤ï¼ˆé«˜æ¸…ã€å­—å¹•ç­‰ï¼‰
        tag_elem = item.find('span', class_='tag') or item.find('span', class_='label') or item.find('span', class_='badge')
        if tag_elem:
            tag_text = clean_text(tag_elem.get_text())
            if tag_text in ['é«˜æ¸…', 'å­—å¹•', 'HD', 'Subtitle', '4K', '1080p', '720p']:
                magnet.tags.append(tag_text)
        
        # ç²å–è¤‡è£½æŒ‰éˆ•çš„éˆæ¥ - é€™æ˜¯é‡é»ï¼
        copy_button = item.find('a', class_='copy-btn') or item.find('button', class_='copy') or item.find('a', string='è¤‡è£½')
        if copy_button:
            magnet.copy_url = copy_button.get('href', '') or copy_button.get('data-url', '') or copy_button.get('data-clipboard-text', '')
        
        # ç²å–ä¸‹è¼‰æŒ‰éˆ•çš„éˆæ¥
        download_button = item.find('a', class_='download-btn') or item.find('button', class_='download') or item.find('a', string='ä¸‹è¼‰')
        if download_button:
            magnet.download_url = download_button.get('href', '') or download_button.get('data-url', '')
        
        # ç²å–æ—¥æœŸ
        date_elem = item.find('span', class_='date') or item.find('td', class_='date')
        if date_elem:
            magnet.date = clean_text(date_elem.get_text())
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°è¤‡è£½æŒ‰éˆ•ï¼Œå˜—è©¦å¾å…¶ä»–å…ƒç´ ç²å–ç£åŠ›éˆæ¥
        if not magnet.copy_url:
            # æŸ¥æ‰¾åŒ…å«ç£åŠ›éˆæ¥çš„å…ƒç´ 
            magnet_link_elem = item.find('a', href=lambda x: x and x.startswith('magnet:'))
            if magnet_link_elem:
                magnet.magnet_url = magnet_link_elem.get('href', '')
                magnet.copy_url = magnet.magnet_url
        
        # èª¿è©¦ä¿¡æ¯
        self.logger.info(f"è§£æç£åŠ›éˆæ¥é …ç›®: æ¨™é¡Œ={magnet.title}, å¤§å°={magnet.size}, æ¨™ç±¤={magnet.tags}, è¤‡è£½éˆæ¥={magnet.copy_url}")
        
        return magnet if magnet.copy_url or magnet.magnet_url else None
    
    def _extract_real_code_from_magnet(self, magnet_url: str) -> str:
        """å¾ç£åŠ›éˆæ¥URLä¸­æå–çœŸå¯¦ç•ªè™Ÿ"""
        if not magnet_url:
            return ""
        
        # å¾ç£åŠ›éˆæ¥URLä¸­æå–ç•ªè™Ÿï¼ˆæ ¼å¼ï¼š[javdb.com]ONSG-098ï¼‰
        code_match = re.search(r'\[javdb\.com\]([A-Z0-9\-]+)', magnet_url)
        if code_match:
            return code_match.group(1)
        
        return ""
    
    def _filter_magnets_by_priority(self, magnet_links: List[MagnetLink]) -> List[MagnetLink]:
        """æ ¹æ“šå„ªå…ˆé †åºé¸æ“‡ä¸€å€‹æœ€ä½³ç£åŠ›éˆæ¥"""
        if not magnet_links:
            return []
        
        # å„ªå…ˆé †åºï¼š1.é«˜æ¸… 2.å­—å¹• 3.ç¬¬ä¸€å€‹
        high_quality = []
        subtitle = []
        
        for magnet in magnet_links:
            has_high_quality = any(tag in magnet.tags for tag in ['é«˜æ¸…', 'HD', '4K', '1080p', '720p'])
            has_subtitle = any(tag in magnet.tags for tag in ['å­—å¹•', 'Subtitle'])
            
            if has_high_quality:
                high_quality.append(magnet)
            elif has_subtitle:
                subtitle.append(magnet)
        
        # æŒ‰å„ªå…ˆé †åºè¿”å›ä¸€å€‹æœ€ä½³é¸æ“‡
        if high_quality:
            self.logger.info(f"é¸æ“‡é«˜æ¸…ç£åŠ›éˆæ¥: {high_quality[0].copy_url}")
            return [high_quality[0]]  # åªè¿”å›ç¬¬ä¸€å€‹é«˜æ¸…
        elif subtitle:
            self.logger.info(f"é¸æ“‡å­—å¹•ç£åŠ›éˆæ¥: {subtitle[0].copy_url}")
            return [subtitle[0]]  # åªè¿”å›ç¬¬ä¸€å€‹å­—å¹•
        else:
            self.logger.info(f"é¸æ“‡ç¬¬ä¸€å€‹ç£åŠ›éˆæ¥: {magnet_links[0].copy_url}")
            return [magnet_links[0]]  # åªè¿”å›ç¬¬ä¸€å€‹
    
    def get_magnet_download_url(self, magnet_link: MagnetLink) -> Optional[str]:
        """ç²å–ç£åŠ›éˆæ¥çš„å¯¦éš›ä¸‹è¼‰URL"""
        if magnet_link.copy_url:
            # å¦‚æœè¤‡è£½æŒ‰éˆ•æœ‰ç›´æ¥çš„URL
            if magnet_link.copy_url.startswith('magnet:'):
                return magnet_link.copy_url
            
            # å¦‚æœæ˜¯ç›¸å°URLï¼Œè½‰æ›ç‚ºçµ•å°URL
            if not magnet_link.copy_url.startswith('http'):
                return urljoin(self.base_url, magnet_link.copy_url)
            
            return magnet_link.copy_url
        
        return magnet_link.magnet_url

class JavDBMagnetManager:
    """JavDB ç£åŠ›éˆæ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.crawler = JavDBMagnetCrawler()
        self.logger = setup_logging()
        self.tracker = DuplicateTracker()
        self.written_urls = set()  # ç”¨æ–¼è·Ÿè¸ªå·²å¯«å…¥çš„URLï¼Œé¿å…é‡è¤‡
    
    def get_top30_magnets(self, skip_duplicates: bool = True, rank_type: str = "monthly") -> List[Dict[str, Any]]:
        """ç²å–æœ‰ç¢¼æ’è¡Œæ¦œå‰30çš„ç£åŠ›éˆæ¥
        
        Args:
            skip_duplicates: æ˜¯å¦è·³éå·²çˆ¬å–çš„å½±ç‰‡
            rank_type: æ’è¡Œæ¦œé¡å‹ ("monthly" æœˆæ¦œ)
        """
        # åªæ”¯æŒæœˆæ¦œ
        if rank_type != "monthly":
            rank_type = "monthly"
            self.logger.warning("å·²å°‡æ’è¡Œæ¦œé¡å‹æ”¹ç‚ºæœˆæ¦œï¼ˆmonthlyï¼‰")
        
        return self.get_top30_monthly_with_duplicate_check() if skip_duplicates else self.crawler.get_monthly_rankings_with_magnets(30)
    
    def get_top30_monthly_with_duplicate_check(self) -> List[Dict[str, Any]]:
        """ç²å–å‰30æœˆæ¦œï¼Œè·³éå·²çˆ¬å–çš„å½±ç‰‡ï¼ˆå…±äº«é‡è¤‡æª¢æ¸¬ï¼‰"""
        # æª¢æŸ¥çµ±è¨ˆä¿¡æ¯
        stats = self.tracker.get_statistics()
        if stats['total_scraped'] > 0:
            self.logger.info(f"ğŸ“Š å·²è¨˜éŒ„ {stats['total_scraped']} éƒ¨å½±ç‰‡ï¼Œå°‡è‡ªå‹•è·³éé‡è¤‡")
        
        self.logger.info("é–‹å§‹ç²å–æœ‰ç¢¼æœˆæ¦œå‰30çš„å½±ç‰‡ç£åŠ›éˆæ¥ï¼ˆæª¢æŸ¥é‡è¤‡ï¼‰")
        
        # 1. ç²å–æ’è¡Œæ¦œé é¢
        rankings_url = f"{self.crawler.base_url}/rankings/movies"
        params = {
            "p": "monthly",  # æœˆæ¦œ
            "t": "censored",  # æœ‰ç¢¼
            "page": 1
        }
        
        response = self.crawler._make_request(rankings_url, params)
        if not response:
            self.logger.error("ç„¡æ³•ç²å–æ’è¡Œæ¦œé é¢")
            return []
        
        # 2. è§£ææ’è¡Œæ¦œï¼Œç²å–å½±ç‰‡åˆ—è¡¨
        all_movies = self.crawler._parse_rankings_page(response.text, 30)
        self.logger.info(f"å¾æœˆæ¦œæ’è¡Œæ¦œç²å–åˆ° {len(all_movies)} éƒ¨å½±ç‰‡")
        
        # 3. éæ¿¾å‡ºæœªçˆ¬å–çš„å½±ç‰‡
        new_movies, skipped_count = self.tracker.get_new_movies(all_movies)
        self.logger.info(f"âœ“ è·³é {skipped_count} éƒ¨å·²çˆ¬å–çš„å½±ç‰‡")
        self.logger.info(f"âœ“ å‰©é¤˜ {len(new_movies)} éƒ¨æ–°å½±ç‰‡")
        
        if not new_movies:
            self.logger.info("æ²’æœ‰æ–°å½±ç‰‡éœ€è¦çˆ¬å–")
            return []
        
        # 4. ä½¿ç”¨å›ºå®šæª”åï¼Œå§‹çµ‚è¿½åŠ æ¨¡å¼
        os.makedirs("magnet", exist_ok=True)
        filename = "magnet/Url List.txt"  # å›ºå®šæª”å
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡éœ€è¦åˆå§‹åŒ– written_urls
        if not os.path.exists(filename):
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ¸…ç©º written_urlsï¼ˆæ–°æ–‡ä»¶ï¼‰
            self.written_urls.clear()
            self.logger.info(f"å‰µå»ºæ–°æ–‡ä»¶: {filename}")
        else:
            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œè®€å–ç¾æœ‰URLåˆ° written_urls ä¸­ï¼ˆé¿å…é‡è¤‡ï¼‰
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    existing_urls = [line.strip() for line in f if line.strip()]
                    self.written_urls.update(existing_urls)
                self.logger.info(f"è¿½åŠ åˆ°ç¾æœ‰æ–‡ä»¶: {filename} (å·²æœ‰ {len(self.written_urls)} å€‹URL)")
            except Exception as e:
                self.logger.warning(f"è®€å–ç¾æœ‰æ–‡ä»¶å¤±æ•—: {e}ï¼Œå°‡ç¹¼çºŒè¿½åŠ ")
        
        file_mode = 'a'  # å§‹çµ‚ä½¿ç”¨è¿½åŠ æ¨¡å¼
        
        # æª¢æŸ¥æ–‡ä»¶æœ€å¾Œä¸€è¡Œæ˜¯å¦ç‚ºä»Šå¤©çš„æ—¥æœŸæ¨™é¡Œ
        current_date = datetime.now().strftime('%Y/%m/%d')
        needs_date_header = True
        if os.path.exists(filename) and os.path.getsize(filename) > 0:
            try:
                with open(filename, 'r', encoding='utf-8') as check_file:
                    lines = check_file.readlines()
                    if lines:
                        # å¾å¾Œå¾€å‰æ‰¾æœ€å¾Œä¸€å€‹éç©ºè¡Œ
                        for line in reversed(lines):
                            last_line = line.strip()
                            if last_line:
                                # æª¢æŸ¥æ˜¯å¦ç‚ºä»Šå¤©çš„æ—¥æœŸæ ¼å¼ YYYY/MM/DD
                                if last_line == current_date:
                                    needs_date_header = False
                                break
            except Exception:
                pass
        
        # 5. ç‚ºæ¯éƒ¨æ–°å½±ç‰‡ç²å–ç£åŠ›éˆæ¥ä¸¦å³æ™‚å¯«å…¥
        results = []
        scraped_codes = []  # è¨˜éŒ„æˆåŠŸçˆ¬å–çš„ç•ªè™Ÿ
        
        with open(filename, file_mode, encoding='utf-8') as f:
            # å¦‚æœéœ€è¦ï¼Œå¯«å…¥æ—¥æœŸæ¨™é¡Œ
            if needs_date_header:
                f.write(f"\n{current_date}\n")
            
            for i, movie in enumerate(new_movies, 1):
                self.logger.info(f"è™•ç†ç¬¬ {i}/{len(new_movies)} éƒ¨æ–°å½±ç‰‡: {movie['title']}")
                
                # ç²å–ç£åŠ›éˆæ¥
                magnet_links = self.crawler.get_movie_magnet_links(movie['detail_url'])
                
                # æ ¹æ“šå„ªå…ˆé †åºéæ¿¾ç£åŠ›éˆæ¥
                filtered_magnets = self.crawler._filter_magnets_by_priority(magnet_links)
                
                # å˜—è©¦å¾ç£åŠ›éˆæ¥ä¸­æå–çœŸå¯¦ç•ªè™Ÿ
                real_code = None
                if filtered_magnets:
                    magnet = filtered_magnets[0]
                    real_code = self.crawler._extract_real_code_from_magnet(magnet.copy_url or magnet.magnet_url)
                    if real_code:
                        movie['code'] = real_code  # æ›´æ–°ç‚ºçœŸå¯¦ç•ªè™Ÿ
                    elif not movie.get('code') or len(movie.get('code', '')) < 5:
                        # å¦‚æœæ²’æœ‰æå–åˆ°çœŸå¯¦ç•ªè™Ÿï¼Œå˜—è©¦å¾æ¨™é¡Œæå–
                        title = movie.get('title', '')
                        code_match = re.search(r'([A-Z]{2,6}-\d{3,5})', title)
                        if code_match:
                            extracted_code = code_match.group(1)
                            movie['code'] = extracted_code
                            real_code = extracted_code
                
                result = {
                    'rank': i,
                    'movie': movie,
                    'magnet_links': filtered_magnets,
                    'total_magnets': len(magnet_links),
                    'filtered_magnets': len(filtered_magnets)
                }
                
                results.append(result)
                
                # å³æ™‚å¯«å…¥åˆ°æ–‡ä»¶ï¼ˆåªä¿å­˜URLï¼Œæª¢æŸ¥é‡è¤‡ï¼‰
                if filtered_magnets:
                    magnet = filtered_magnets[0]  # åªå–ç¬¬ä¸€å€‹ï¼ˆæœ€ä½³é¸æ“‡ï¼‰
                    url = magnet.copy_url or magnet.magnet_url
                    # æ¨™æº–åŒ–URLï¼ˆå»é™¤é¦–å°¾ç©ºæ ¼ï¼‰
                    if url:
                        url = url.strip()
                    # æª¢æŸ¥URLæ˜¯å¦å·²ç¶“å¯«å…¥éï¼ˆé¿å…é‡è¤‡ï¼‰
                    if url and url not in self.written_urls:
                        f.write(f"{url}\n")
                        self.written_urls.add(url)  # è¨˜éŒ„å·²å¯«å…¥çš„URL
                        # ä½¿ç”¨çœŸå¯¦ç•ªè™Ÿè¨˜éŒ„ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦å‰‡ä½¿ç”¨åŸå§‹ code
                        code_to_record = real_code or movie.get('code', '')
                        # é©—è­‰ç•ªè™Ÿæ ¼å¼ï¼Œåªè¨˜éŒ„æœ‰æ•ˆçš„ç•ªè™Ÿ
                        if code_to_record and self.tracker._is_valid_code(code_to_record):
                            scraped_codes.append(code_to_record)
                        else:
                            # å¦‚æœç•ªè™Ÿæ ¼å¼ç•°å¸¸ï¼Œè¨˜éŒ„è­¦å‘Šä½†ç¹¼çºŒè™•ç†
                            if code_to_record:
                                self.logger.warning(f"è·³éè¨˜éŒ„ç•°å¸¸æ ¼å¼çš„ç•ªè™Ÿ: {code_to_record} (æ¨™é¡Œ: {movie.get('title', '')})")
                    elif url and url in self.written_urls:
                        self.logger.info(f"è·³éé‡è¤‡URL: {url}")
                
                f.flush()  # å¼·åˆ¶å¯«å…¥ï¼Œç¢ºä¿å³æ™‚ä¿å­˜
                
                # é¿å…è«‹æ±‚éæ–¼é »ç¹
                from utils import random_delay
                random_delay(2, 4)
        
        self.logger.info(f"ç£åŠ›éˆæ¥å·²å³æ™‚ä¿å­˜åˆ°: {filename}")
        
        # 6. æ¨™è¨˜å·²çˆ¬å–çš„å½±ç‰‡
        if scraped_codes:
            self.tracker.batch_mark_as_scraped([{'code': code} for code in scraped_codes])
            self.logger.info(f"å·²æ¨™è¨˜ {len(scraped_codes)} éƒ¨å½±ç‰‡ç‚ºå·²çˆ¬å–")
        
        return results
    
    def get_magnets_by_code(self, movie_code: str) -> List[MagnetLink]:
        """æ ¹æ“šç•ªè™Ÿç²å–ç£åŠ›éˆæ¥"""
        movie_url = f"{self.crawler.base_url}/v/{movie_code}"
        return self.crawler.get_movie_magnet_links(movie_url)
    
    def export_magnets_to_file(self, results: List[Dict[str, Any]], 
                              filename: str = None) -> str:
        """å°å‡ºç£åŠ›éˆæ¥åˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"magnet/javdb_magnets_{timestamp}.txt"
        
        # ç¢ºä¿ magnet è³‡æ–™å¤¾å­˜åœ¨
        os.makedirs("magnet", exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("JavDB æœ‰ç¢¼æœˆæ¦œå‰30ç£åŠ›éˆæ¥\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n\n")
            
            # çµ±è¨ˆä¿¡æ¯
            total_movies = len(results)
            total_magnets = sum(result['total_magnets'] for result in results)
            filtered_magnets = sum(result['filtered_magnets'] for result in results)
            
            f.write(f"çµ±è¨ˆä¿¡æ¯:\n")
            f.write(f"ç¸½å½±ç‰‡æ•¸: {total_movies}\n")
            f.write(f"ç¸½ç£åŠ›éˆæ¥æ•¸: {total_magnets}\n")
            f.write(f"éæ¿¾å¾Œç£åŠ›éˆæ¥æ•¸: {filtered_magnets}\n")
            f.write(f"æˆåŠŸç‡: {filtered_magnets/total_magnets*100:.1f}%\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("ç£åŠ›éˆæ¥åˆ—è¡¨\n")
            f.write("=" * 80 + "\n\n")
            
            for result in results:
                movie = result['movie']
                f.write(f"æ’å: {result['rank']}\n")
                f.write(f"ç•ªè™Ÿ: {movie['code']}\n")
                f.write(f"æ¨™é¡Œ: {movie['title']}\n")
                f.write(f"æ¼”å“¡: {', '.join(movie['actors'])}\n")
                f.write(f"è©•åˆ†: {movie['score']}\n")
                f.write(f"ç¸½ç£åŠ›éˆæ¥: {result['total_magnets']} å€‹\n")
                f.write(f"éæ¿¾å¾Œç£åŠ›éˆæ¥: {result['filtered_magnets']} å€‹\n")
                
                if result['magnet_links']:
                    f.write("ç£åŠ›éˆæ¥:\n")
                    for i, magnet in enumerate(result['magnet_links'], 1):
                        f.write(f"  {i}. {magnet.title}\n")
                        f.write(f"     å¤§å°: {magnet.size}\n")
                        f.write(f"     æ¨™ç±¤: {', '.join(magnet.tags)}\n")
                        f.write(f"     ä¸‹è¼‰éˆæ¥: {magnet.copy_url or magnet.magnet_url}\n")
                        f.write(f"     æ—¥æœŸ: {magnet.date}\n")
                        f.write("\n")
                else:
                    f.write("ç„¡ç¬¦åˆæ¢ä»¶çš„ç£åŠ›éˆæ¥\n")
                
                f.write("-" * 80 + "\n\n")
            
            # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ç´”ç£åŠ›éˆæ¥åˆ—è¡¨
            f.write("=" * 80 + "\n")
            f.write("ç´”ç£åŠ›éˆæ¥åˆ—è¡¨ï¼ˆæ–¹ä¾¿è¤‡è£½ï¼‰\n")
            f.write("=" * 80 + "\n\n")
            
            magnet_count = 0
            for result in results:
                if result['magnet_links']:
                    for magnet in result['magnet_links']:
                        magnet_count += 1
                        f.write(f"{magnet_count}. {magnet.copy_url or magnet.magnet_url}\n")
            
            f.write(f"\nç¸½å…± {magnet_count} å€‹ç£åŠ›éˆæ¥\n")
        
        self.logger.info(f"ç£åŠ›éˆæ¥å·²å°å‡ºåˆ°: {filename}")
        return filename
    
    def get_summary_stats(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆæ‘˜è¦"""
        total_movies = len(results)
        total_magnets = sum(result['total_magnets'] for result in results)
        filtered_magnets = sum(result['filtered_magnets'] for result in results)
        
        movies_with_magnets = sum(1 for result in results if result['filtered_magnets'] > 0)
        
        return {
            'total_movies': total_movies,
            'total_magnets': total_magnets,
            'filtered_magnets': filtered_magnets,
            'movies_with_magnets': movies_with_magnets,
            'success_rate': movies_with_magnets / total_movies if total_movies > 0 else 0
        }

