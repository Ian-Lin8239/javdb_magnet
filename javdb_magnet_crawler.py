"""
JavDB ç£åŠ›éˆæ¥å°ˆç”¨çˆ¬èŸ²
å°ˆé–€ç”¨æ–¼ç²å–æœ‰ç¢¼æœˆæ¦œå‰30çš„ç£åŠ›éˆæ¥ä¸‹è¼‰ä½ç½®
"""
import time
import random
import re
import os
from typing import List, Optional, Dict, Any
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlencode
from datetime import datetime

# ä½¿ç”¨ curl_cffi æ¨¡æ“¬ Chrome TLS æŒ‡ç´‹ä»¥é€šé Cloudflareï¼ˆrequests æœƒè¢« 403ï¼‰
try:
    from curl_cffi import requests as cffi_requests
    _USE_CFFI = True
except ImportError:
    import requests as cffi_requests
    _USE_CFFI = False
import requests  # ä»ç”¨æ–¼ RequestException ç­‰

# 403 æ™‚æ”¹ç”¨ Playwright çœŸå¯¦ç€è¦½å™¨å–å¾—é é¢ï¼ˆéœ€ pip install playwright && playwright install chromiumï¼‰
try:
    from playwright.sync_api import sync_playwright
    _USE_PLAYWRIGHT = True
except ImportError:
    _USE_PLAYWRIGHT = False


class _FakeResponse:
    """ä¾›è§£æç”¨çš„ç°¡æ˜“ responseï¼Œåƒ…å« .text / .status_code / .url"""
    __slots__ = ("text", "status_code", "url")
    def __init__(self, text: str, status_code: int = 200, url: str = ""):
        self.text = text
        self.status_code = status_code
        self.url = url

# å›ºå®šæ¡Œé¢ Chrome UAï¼Œé¿å… Cloudflare å› éš¨æ©Ÿ/è¡Œå‹• UA å›å‚³ 403
FIXED_CHROME_UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
# å¹´é½¡é©—è­‰ï¼šé»ã€Œæ˜¯,æˆ‘å·²æ»¿18æ­²ã€æ™‚ç€è¦½å™¨æœƒè«‹æ±‚æ­¤ URLï¼Œä¼ºæœå™¨ 302 ä¸¦è¨­å®š cookie
OVER18_URL = "/over18?respond=1"
from utils import (
    get_random_user_agent, random_delay, clean_text, setup_logging
)
from duplicate_tracker import DuplicateTracker

class MagnetLink:
    """ç£åŠ›éˆæ¥æ•¸æ“šæ¨¡å‹"""
    def __init__(self):
        self.title = ""  # ç£åŠ›éˆæ¥æ¨™é¡Œ
        self.size = ""  # æ–‡ä»¶å¤§å°
        self.file_count = 0  # æ–‡ä»¶æ•¸é‡
        self.tags = []  # æ¨™ç±¤ (é«˜æ¸…, å­—å¹•ç­‰)
        self.magnet_url = ""  # ç£åŠ›éˆæ¥URL
        self.copy_url = ""  # è¤‡è£½æŒ‰éˆ•çš„å¯¦éš›ä¸‹è¼‰éˆæ¥
        self.download_url = ""  # ä¸‹è¼‰æŒ‰éˆ•çš„éˆæ¥
        self.date = ""  # ä¸Šå‚³æ—¥æœŸ
        self.quality = ""  # è³ªé‡æ¨™è­˜

class JavDBMagnetCrawler:
    """JavDB ç£åŠ›éˆæ¥å°ˆç”¨çˆ¬èŸ²"""
    
    def __init__(self):
        self.base_url = "https://javdb.com"
        if _USE_CFFI:
            self.session = cffi_requests.Session(impersonate="chrome")
        else:
            self.session = requests.Session()
        self.logger = setup_logging()
        self._setup_session()
        if _USE_CFFI:
            self.logger.info("ä½¿ç”¨ curl_cffi æ¨¡æ“¬ Chrome TLSï¼ˆimpersonate=chromeï¼‰")
        else:
            self.logger.warning("æœªå®‰è£ curl_cffiï¼Œä½¿ç”¨ requestsï¼Œå¯èƒ½é­é‡ 403ï¼Œè«‹åŸ·è¡Œ: pip install curl_cffi")
        if _USE_PLAYWRIGHT:
            self.logger.info("Playwright å‚™æ´å·²å•Ÿç”¨ï¼ˆ403 æ™‚å°‡ç”¨çœŸå¯¦ç€è¦½å™¨å–å¾—é é¢ï¼‰")
        else:
            self.logger.info("è‹¥æŒçºŒ 403ï¼Œå¯å®‰è£ Playwright å‚™æ´: pip install playwright å¾ŒåŸ·è¡Œ playwright install chromium")
    
    def _setup_session(self):
        """è¨­ç½®æœƒè©±"""
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Referer": "https://javdb.com/",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0",
            "DNT": "1",
            "Sec-GPC": "1"
        })
        # JavDB 18 æ­²ç¢ºèªï¼šç›´æ¥å¸¶å…¥ over18=1ï¼Œç„¡éœ€å…ˆè«‹æ±‚ over18 é é¢
        self.session.cookies.set("over18", "1", domain="javdb.com", path="/")
    
    def _fetch_with_playwright(self, full_url: str) -> Optional[_FakeResponse]:
        """403 æ™‚ç”¨çœŸå¯¦ç€è¦½å™¨å–å¾—é é¢ã€‚éœ€å®‰è£ playwright ä¸¦åŸ·è¡Œ playwright install chromiumã€‚"""
        if not _USE_PLAYWRIGHT:
            return None
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                context = browser.new_context(
                    locale="zh-TW",
                    viewport={"width": 1280, "height": 720},
                )
                context.add_cookies([{"name": "over18", "value": "1", "domain": "javdb.com", "path": "/"}])
                page = context.new_page()
                page.goto(full_url, wait_until="domcontentloaded", timeout=30000)
                # è‹¥æœ‰å¹´é½¡é©—è­‰å½ˆçª—ï¼Œé»ã€Œæ˜¯,æˆ‘å·²æ»¿18æ­²ã€
                try:
                    btn = page.get_by_role("button", name="æ˜¯")
                    if btn.is_visible(timeout=2000):
                        btn.click()
                        page.wait_for_load_state("networkidle", timeout=10000)
                except Exception:
                    pass
                html = page.content()
                browser.close()
                return _FakeResponse(html, 200, full_url)
        except Exception as e:
            self.logger.warning(f"Playwright å‚™æ´å¤±æ•—: {e}")
            return None
    
    def _make_request(self, url: str, params: Optional[Dict] = None, 
                     retries: int = 3, skip_ua_rotation: bool = False,
                     extra_headers: Optional[Dict[str, str]] = None) -> Optional[Any]:
        """ç™¼é€HTTPè«‹æ±‚ã€‚skip_ua_rotation=True æ™‚ä¸æ›´æ› UAï¼ˆç”¨æ–¼å…ˆè¨ªé¦–é å†è«‹æ±‚æ’è¡Œæ¦œä»¥é€šé Cloudflareï¼‰ã€‚"""
        for attempt in range(retries + 1):
            try:
                # éš¨æ©Ÿå»¶é²
                if attempt > 0:
                    random_delay(2, 5)
                
                # æ›´æ–°User-Agentï¼ˆè‹¥æœªè¦æ±‚å›ºå®š UAï¼‰
                if not skip_ua_rotation:
                    self.session.headers['User-Agent'] = get_random_user_agent()
                req_headers = {'Accept-Encoding': 'gzip, deflate'}
                if extra_headers:
                    req_headers.update(extra_headers)
                # æ¯æ¬¡è«‹æ±‚éƒ½æ˜ç¢ºå¸¶ä¸Š over18ï¼Œç¢ºä¿ curl_cffi çš„ cookie jar æœ‰é€å‡º
                req_cookies = {"over18": "1"}
                response = self.session.get(
                    url,
                    params=params,
                    timeout=30,
                    allow_redirects=True,
                    headers=req_headers,
                    cookies=req_cookies
                )
                
                response.raise_for_status()
                # è«‹æ±‚é–“éš” - å¢åŠ å»¶é²ä»¥é™ä½è¢«å°é–çš„é¢¨éšª
                random_delay(2, 4)  # å¾ 1-3ç§’ å¢åŠ åˆ° 2-4ç§’
                
                return response
                
            except Exception as e:
                self.logger.warning(f"è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt + 1}/{retries + 1}): {e}")
                
                if attempt == retries:
                    # è‹¥ç‚º 403 ä¸”å·²å®‰è£ Playwrightï¼Œæ”¹ç”¨çœŸå¯¦ç€è¦½å™¨å–å¾—é é¢
                    err_resp = getattr(e, "response", None)
                    if err_resp is not None and err_resp.status_code == 403 and _USE_PLAYWRIGHT:
                        full_url = url + ("?" + urlencode(params)) if params else url
                        self.logger.info("æ”¶åˆ° 403ï¼Œå˜—è©¦ä½¿ç”¨ Playwright çœŸå¯¦ç€è¦½å™¨å–å¾—é é¢...")
                        pw_resp = self._fetch_with_playwright(full_url)
                        if pw_resp is not None:
                            self.logger.info("Playwright å–å¾—é é¢æˆåŠŸ")
                            return pw_resp
                    self.logger.error(f"è«‹æ±‚æœ€çµ‚å¤±æ•—: {url}")
                    return None
                
                # æŒ‡æ•¸é€€é¿
                time.sleep(2 ** attempt)
        
        return None
    
    def get_monthly_rankings_with_magnets(self, limit: int = 30) -> List[Dict[str, Any]]:
        """ç²å–æœ‰ç¢¼æœˆæ¦œå‰30çš„å½±ç‰‡åŠå…¶ç£åŠ›éˆæ¥"""
        self.logger.info(f"é–‹å§‹ç²å–æœ‰ç¢¼æœˆæ¦œå‰{limit}çš„å½±ç‰‡ç£åŠ›éˆæ¥")
        
        # ç›´æ¥è«‹æ±‚æ’è¡Œæ¦œï¼ˆå·²å¸¶ over18=1 cookie èˆ‡ Chrome TLSï¼‰ï¼Œä¸å†å…ˆè¨ªé¦–é é¿å…è§¸ç™¼ 403
        self.session.headers['User-Agent'] = FIXED_CHROME_UA
        # 1. ç²å–æ’è¡Œæ¦œé é¢
        rankings_url = f"{self.base_url}/rankings/movies"
        params = {
            "p": "monthly",  # æœˆæ¦œ
            "t": "censored",  # æœ‰ç¢¼
            "page": 1
        }
        response = self._make_request(
            rankings_url, params,
            skip_ua_rotation=True,
            extra_headers={"Referer": self.base_url + "/"}
        )
        if not response:
            self.logger.error("ç„¡æ³•ç²å–æ’è¡Œæ¦œé é¢")
            return []
        
        # 2. è§£ææ’è¡Œæ¦œï¼Œç²å–å½±ç‰‡åˆ—è¡¨
        movies = self._parse_rankings_page(response.text, limit)
        self.logger.info(f"å¾æ’è¡Œæ¦œç²å–åˆ° {len(movies)} éƒ¨å½±ç‰‡")
        
        # 3. å‰µå»ºå³æ™‚å¯«å…¥æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"magnet/javdb_monthly_magnets_{timestamp}.txt"
        os.makedirs("magnet", exist_ok=True)
        
        # 4. ç‚ºæ¯éƒ¨å½±ç‰‡ç²å–ç£åŠ›éˆæ¥ä¸¦å³æ™‚å¯«å…¥
        results = []
        with open(filename, 'w', encoding='utf-8') as f:
            # å¯«å…¥æ–‡ä»¶é ­
            f.write("JavDB æœ‰ç¢¼æœˆæ¦œå‰30ç£åŠ›éˆæ¥\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n\n")
            f.write("ç£åŠ›éˆæ¥åˆ—è¡¨ï¼ˆå³æ™‚æ›´æ–°ï¼‰\n")
            f.write("=" * 80 + "\n\n")
            f.flush()  # å¼·åˆ¶å¯«å…¥
            
            for i, movie in enumerate(movies, 1):
                self.logger.info(f"è™•ç†ç¬¬ {i}/{len(movies)} éƒ¨å½±ç‰‡: {movie['title']}")
                
                # ç²å–ç£åŠ›éˆæ¥
                magnet_links = self.get_movie_magnet_links(movie['detail_url'])
                
                # æ ¹æ“šå„ªå…ˆé †åºéæ¿¾ç£åŠ›éˆæ¥
                filtered_magnets = self._filter_magnets_by_priority(magnet_links)
                
                result = {
                    'rank': i,
                    'movie': movie,
                    'magnet_links': filtered_magnets,
                    'total_magnets': len(magnet_links),
                    'filtered_magnets': len(filtered_magnets)
                }
                
                # å˜—è©¦å¾ç£åŠ›éˆæ¥ä¸­æå–çœŸå¯¦ç•ªè™Ÿ
                if filtered_magnets and (not movie['code'] or len(movie['code']) < 5):
                    magnet = filtered_magnets[0]
                    real_code = self._extract_real_code_from_magnet(magnet.copy_url or magnet.magnet_url)
                    if real_code:
                        movie['code'] = real_code
                
                results.append(result)
                
                # å³æ™‚å¯«å…¥åˆ°æ–‡ä»¶
                f.write(f"æ’å: {i}\n")
                f.write(f"ç•ªè™Ÿ: {movie['code']}\n")
                f.write(f"æ¨™é¡Œ: {movie['title']}\n")
                f.write(f"æ¼”å“¡: {', '.join(movie['actors'])}\n")
                f.write(f"è©•åˆ†: {movie['score']}\n")
                f.write(f"ç¸½ç£åŠ›éˆæ¥: {len(magnet_links)} å€‹\n")
                f.write(f"é¸æ“‡ç£åŠ›éˆæ¥: {len(filtered_magnets)} å€‹\n")
                
                if filtered_magnets:
                    magnet = filtered_magnets[0]  # åªå–ç¬¬ä¸€å€‹ï¼ˆæœ€ä½³é¸æ“‡ï¼‰
                    f.write(f"ç£åŠ›éˆæ¥: {magnet.copy_url or magnet.magnet_url}\n")
                    f.write(f"å¤§å°: {magnet.size}\n")
                    f.write(f"æ¨™ç±¤: {', '.join(magnet.tags)}\n")
                    f.write(f"æ—¥æœŸ: {magnet.date}\n")
                else:
                    f.write("ç„¡ç¬¦åˆæ¢ä»¶çš„ç£åŠ›éˆæ¥\n")
                
                f.write("-" * 80 + "\n\n")
                f.flush()  # å¼·åˆ¶å¯«å…¥ï¼Œç¢ºä¿å³æ™‚ä¿å­˜
                
                # é¿å…è«‹æ±‚éæ–¼é »ç¹
                random_delay(2, 4)
            
            # å¯«å…¥çµ±è¨ˆä¿¡æ¯
            total_magnets = sum(result['total_magnets'] for result in results)
            filtered_magnets = sum(result['filtered_magnets'] for result in results)
            
            f.write("=" * 80 + "\n")
            f.write("çµ±è¨ˆä¿¡æ¯\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç¸½å½±ç‰‡æ•¸: {len(results)}\n")
            f.write(f"ç¸½ç£åŠ›éˆæ¥æ•¸: {total_magnets}\n")
            f.write(f"é¸æ“‡ç£åŠ›éˆæ¥æ•¸: {filtered_magnets}\n")
            f.write(f"æˆåŠŸç‡: {filtered_magnets/total_magnets*100:.1f}%\n")
            f.write(f"å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        self.logger.info(f"ç£åŠ›éˆæ¥å·²å³æ™‚ä¿å­˜åˆ°: {filename}")
        return results
    
    def _parse_rankings_page(self, html_content: str, limit: int) -> List[Dict[str, Any]]:
        """è§£ææ’è¡Œæ¦œé é¢"""
        soup = BeautifulSoup(html_content, 'html.parser')
        movies = []
        
        self.logger.info(f"é é¢å…§å®¹é•·åº¦: {len(html_content)}")
        
        # æŸ¥æ‰¾é›»å½±åˆ—è¡¨å®¹å™¨
        movie_items = soup.find_all('div', class_='item')
        self.logger.info(f"æ‰¾åˆ° {len(movie_items)} å€‹é›»å½±é …ç›®")
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦å…¶ä»–é¸æ“‡å™¨
        if not movie_items:
            movie_items = soup.find_all('div', class_='movie-item')
            self.logger.info(f"ä½¿ç”¨ movie-item æ‰¾åˆ° {len(movie_items)} å€‹é …ç›®")
        
        if not movie_items:
            movie_items = soup.find_all('div', class_='video-item')
            self.logger.info(f"ä½¿ç”¨ video-item æ‰¾åˆ° {len(movie_items)} å€‹é …ç›®")
        
        
        for index, item in enumerate(movie_items[:limit]):
            try:
                movie = self._parse_movie_item(item, index + 1)
                if movie:
                    movies.append(movie)
            except Exception as e:
                self.logger.warning(f"è§£æé›»å½±é …ç›®å¤±æ•—: {e}")
                continue
        
        return movies
    
    def _parse_movie_item(self, item, rank: int) -> Optional[Dict[str, Any]]:
        """è§£æé›»å½±é …ç›®"""
        movie = {
            'rank': rank,
            'code': '',
            'title': '',
            'detail_url': '',
            'cover_url': '',
            'score': 0.0,
            'actors': [],
            'tags': []
        }
        
        # ç²å–é›»å½±éˆæ¥
        link_elem = item.find('a')
        if not link_elem:
            return None
        
        movie['detail_url'] = urljoin(self.base_url, link_elem.get('href', ''))
        
        # å¾URLæå–ç•ªè™Ÿï¼ˆé€™æ˜¯JavDBçš„çŸ­ä»£ç¢¼ï¼Œä¸æ˜¯çœŸå¯¦ç•ªè™Ÿï¼‰
        url_parts = movie['detail_url'].split('/')
        if len(url_parts) > 1:
            movie['code'] = url_parts[-1]  # çŸ­ä»£ç¢¼ï¼Œå¾ŒçºŒæœƒå˜—è©¦å¾ç£åŠ›éˆæ¥æå–çœŸå¯¦ç•ªè™Ÿ
        
        # ç²å–å°é¢åœ–ç‰‡
        img_elem = item.find('img')
        if img_elem:
            movie['cover_url'] = urljoin(self.base_url, img_elem.get('src', ''))
        
        # ç²å–æ¨™é¡Œ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        title_elem = item.find('div', class_='video-title')
        if not title_elem:
            title_elem = item.find('div', class_='title')
        if not title_elem:
            title_elem = item.find('strong')
        if not title_elem:
            # å˜—è©¦å¾éˆæ¥æ–‡æœ¬ç²å–
            title_elem = link_elem
        
        if title_elem:
            if title_elem.name == 'a':
                title_text = title_elem.get('title', '') or title_elem.get_text()
            else:
                title_link = title_elem.find('a')
                if title_link:
                    title_text = title_link.get('title', '') or title_link.get_text()
                else:
                    title_text = title_elem.get_text()
            
            if title_text:
                movie['title'] = clean_text(title_text)
        
        # ç²å–è©•åˆ† - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        score_elem = item.find('span', class_='score')
        if not score_elem:
            score_elem = item.find('span', class_='rating')
        if not score_elem:
            score_elem = item.find('div', class_='score')
        if not score_elem:
            score_elem = item.find('span', class_='value')
        if score_elem:
            try:
                score_text = score_elem.get_text().strip()
                # ç§»é™¤å¯èƒ½çš„éæ•¸å­—å­—ç¬¦ï¼Œåªä¿ç•™æ•¸å­—å’Œå°æ•¸é»
                score_text = re.sub(r'[^\d.]', '', score_text)
                if score_text:
                    movie['score'] = float(score_text)
            except (ValueError, AttributeError):
                pass
        
        # ç²å–æ¨™ç±¤
        tags_elem = item.find('div', class_='tags')
        if not tags_elem:
            tags_elem = item.find('div', class_='tag-list')
        if tags_elem:
            tag_links = tags_elem.find_all('a')
            movie['tags'] = [clean_text(tag.get_text()) for tag in tag_links]
        
        # ç²å–æ¼”å“¡ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        actors_elem = item.find('div', class_='actors')
        if not actors_elem:
            actors_elem = item.find('div', class_='actor-list')
        if not actors_elem:
            actors_elem = item.find('div', class_='performers')
        if not actors_elem:
            # å˜—è©¦æŸ¥æ‰¾åŒ…å«"æ¼”å“¡"æˆ–"ä¸»æ¼”"æ–‡å­—çš„div
            for div in item.find_all('div'):
                div_text = div.get_text()
                if 'æ¼”å“¡' in div_text or 'ä¸»æ¼”' in div_text:
                    actors_elem = div
                    break
        
        if actors_elem:
            actor_links = actors_elem.find_all('a')
            if actor_links:
                movie['actors'] = [clean_text(actor.get_text()) for actor in actor_links]
            else:
                # å¦‚æœæ²’æœ‰éˆæ¥ï¼Œå˜—è©¦ç›´æ¥ç²å–æ–‡æœ¬ä¸¦åˆ†å‰²
                actor_text = actors_elem.get_text().strip()
                if actor_text:
                    # ç§»é™¤"æ¼”å“¡ï¼š"ç­‰å‰ç¶´
                    actor_text = re.sub(r'^[æ¼”å“¡ä¸»æ¼”ï¼š:]+', '', actor_text)
                    if actor_text:
                        movie['actors'] = [clean_text(a.strip()) for a in actor_text.split(',') if a.strip()]
        
        return movie
    
    def search_movie_by_code(self, movie_code: str) -> Optional[str]:
        """é€šéç•ªè™Ÿæœç´¢æ‰¾åˆ°æ­£ç¢ºçš„å½±ç‰‡ URL
        
        Returns:
            æ‰¾åˆ°çš„å½±ç‰‡è©³æƒ…é  URLï¼Œå¦‚æœæœªæ‰¾åˆ°å‰‡è¿”å› None
        """
        search_url = f"{self.base_url}/search"
        params = {"q": movie_code}
        
        response = self._make_request(search_url, params)
        if not response:
            self.logger.error(f"ç„¡æ³•ç²å–æœç´¢é é¢: {search_url}")
            return None
        
        # è§£ææœç´¢çµæœï¼Œæ‰¾åˆ°ç¬¬ä¸€å€‹åŒ¹é…çš„å½±ç‰‡
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # å˜—è©¦å¤šç¨®é¸æ“‡å™¨ä¾†æ‰¾åˆ°å½±ç‰‡é …ç›®ï¼ˆèˆ‡æ’è¡Œæ¦œé¡ä¼¼ï¼‰
        movie_items = soup.find_all('div', class_='item')
        if not movie_items:
            movie_items = soup.find_all('div', class_='movie-item')
        if not movie_items:
            movie_items = soup.find_all('div', class_='video-item')
        
        # éæ­·æœç´¢çµæœï¼Œæ‰¾åˆ°åŒ…å«ç›®æ¨™ç•ªè™Ÿçš„å½±ç‰‡
        for item in movie_items:
            link_elem = item.find('a')
            if not link_elem:
                continue
            
            detail_url = urljoin(self.base_url, link_elem.get('href', ''))
            
            # å˜—è©¦è§£æå½±ç‰‡é …ç›®ç²å–ç•ªè™Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
            movie_data = self._parse_movie_item(item, 0)
            if movie_data:
                # æª¢æŸ¥æ¨™é¡Œæˆ–ä»£ç¢¼æ˜¯å¦åŒ…å«ç›®æ¨™ç•ªè™Ÿ
                code_in_title = movie_code.upper() in (movie_data.get('code', '') or '').upper()
                code_in_title_text = movie_code.upper() in (movie_data.get('title', '') or '').upper()
                
                # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„ç•ªè™Ÿï¼Œè¿”å›è©²å½±ç‰‡çš„ URL
                if code_in_title or code_in_title_text:
                    self.logger.info(f"é€šéæœç´¢æ‰¾åˆ°å½±ç‰‡: {detail_url} (ç•ªè™Ÿ: {movie_data.get('code', '')})")
                    return detail_url
            else:
                # å¦‚æœç„¡æ³•è§£æï¼Œè‡³å°‘è¿”å›ç¬¬ä¸€å€‹çµæœçš„ URLï¼ˆé€šå¸¸æœç´¢çµæœçš„ç¬¬ä¸€å€‹æœ€ç›¸é—œï¼‰
                if item == movie_items[0]:
                    self.logger.info(f"è¿”å›æœç´¢çµæœç¬¬ä¸€å€‹å½±ç‰‡: {detail_url}")
                    return detail_url
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°åŒ¹é…é …ï¼Œä½†æœç´¢çµæœå­˜åœ¨ï¼Œè¿”å›ç¬¬ä¸€å€‹çµæœ
        if movie_items:
            link_elem = movie_items[0].find('a')
            if link_elem:
                detail_url = urljoin(self.base_url, link_elem.get('href', ''))
                self.logger.warning(f"æœªæ‰¾åˆ°ç²¾ç¢ºåŒ¹é…ï¼Œè¿”å›æœç´¢çµæœç¬¬ä¸€å€‹å½±ç‰‡: {detail_url}")
                return detail_url
        
        self.logger.warning(f"æœªæ‰¾åˆ°ç•ªè™Ÿ {movie_code} çš„å½±ç‰‡")
        return None
    
    def get_movie_magnet_links(self, movie_url: str) -> List[MagnetLink]:
        """ç²å–å½±ç‰‡çš„ç£åŠ›éˆæ¥"""
        self.logger.info(f"ç²å–ç£åŠ›éˆæ¥: {movie_url}")
        
        response = self._make_request(movie_url)
        if not response:
            self.logger.error(f"ç„¡æ³•ç²å–å½±ç‰‡è©³æƒ…é é¢: {movie_url}")
            return []
        
        return self._parse_magnet_links_page(response.text, movie_url)
    
    def _parse_magnet_links_page(self, html_content: str, movie_url: str) -> List[MagnetLink]:
        """è§£æç£åŠ›éˆæ¥é é¢"""
        soup = BeautifulSoup(html_content, 'html.parser')
        magnet_links = []
        error_indicators = ['é©—è­‰ç¢¼', 'ç™»éŒ„', 'è«‹ç™»å…¥', 'éœ€è¦ç™»éŒ„', 'captcha', 'login', 'è«‹ç¨å¾Œå†è©¦', 'è¨ªå•éæ–¼é »ç¹']
        page_text_lower = html_content.lower()
        
        # æŸ¥æ‰¾ç£åŠ›éˆæ¥å€åŸŸ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        magnet_section = None
        
        # å˜—è©¦ä¸åŒçš„é¸æ“‡å™¨
        selectors = [
            'div.magnet-links',
            'div#magnet-links', 
            'div.links',
            'div.magnet-list',
            'div.torrent-list',
            'div[class*="magnet"]',
            'div[class*="torrent"]'
        ]
        
        for selector in selectors:
            magnet_section = soup.select_one(selector)
            if magnet_section:
                self.logger.info(f"æ‰¾åˆ°ç£åŠ›éˆæ¥å€åŸŸ: {selector}")
                break
        
        if not magnet_section:
            # å¦‚æœæ‰¾ä¸åˆ°å°ˆé–€çš„ç£åŠ›éˆæ¥å€åŸŸï¼ŒæŸ¥æ‰¾åŒ…å«"è¤‡è£½"æŒ‰éˆ•çš„å€åŸŸ
            copy_buttons = soup.find_all('a', string='è¤‡è£½')
            if copy_buttons:
                self.logger.info(f"æ‰¾åˆ° {len(copy_buttons)} å€‹è¤‡è£½æŒ‰éˆ•")
                # å¾è¤‡è£½æŒ‰éˆ•å‘ä¸ŠæŸ¥æ‰¾çˆ¶å®¹å™¨
                for button in copy_buttons:
                    parent = button.find_parent('div') or button.find_parent('tr')
                    if parent:
                        magnet_link = self._parse_magnet_item(parent)
                        if magnet_link:
                            magnet_links.append(magnet_link)
                if magnet_links:
                    return magnet_links
            
            # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œå˜—è©¦å¾HTMLä¸­ç›´æ¥æå–magnetéˆæ¥ï¼ˆä½¿ç”¨æ­£å‰‡è¡¨é”å¼ï¼‰
            self.logger.warning("æœªæ‰¾åˆ°ç£åŠ›éˆæ¥å€åŸŸå’Œè¤‡è£½æŒ‰éˆ•ï¼Œå˜—è©¦å¾HTMLä¸­ç›´æ¥æå–")
            magnet_pattern = r'magnet:\?xt=urn:btih:[a-zA-Z0-9]+[^"\s<>]*'
            found_magnets = re.findall(magnet_pattern, html_content)
            if found_magnets:
                self.logger.info(f"å¾HTMLä¸­ç›´æ¥æå–åˆ° {len(found_magnets)} å€‹ç£åŠ›éˆæ¥")
                for magnet_url in found_magnets[:10]:  # æœ€å¤šå–å‰10å€‹ï¼Œé¿å…éå¤š
                    # å‰µå»ºä¸€å€‹ç°¡å–®çš„MagnetLinkå°è±¡
                    magnet_link = MagnetLink()
                    magnet_link.title = f"ç£åŠ›éˆæ¥ {len(magnet_links) + 1}"
                    magnet_link.magnet_url = magnet_url
                    magnet_link.copy_url = magnet_url
                    magnet_link.size = "æœªçŸ¥"
                    magnet_link.tags = []
                    magnet_link.file_count = 0
                    magnet_link.date = ""
                    magnet_links.append(magnet_link)
                    self.logger.info(f"æˆåŠŸæå–ç£åŠ›éˆæ¥: {magnet_url[:50]}...")
            
            if not magnet_links:
                self.logger.warning("ç„¡æ³•å¾é é¢ä¸­æå–ä»»ä½•ç£åŠ›éˆæ¥")
                for ind in error_indicators:
                    if ind.lower() in page_text_lower:
                        self.logger.warning(f"é é¢å¯èƒ½åŒ…å«éŒ¯èª¤æç¤ºï¼ˆ{ind}ï¼‰ï¼Œç¶²ç«™å¯èƒ½é™åˆ¶äº†è¨ªå•")
                        break
                return []
            return magnet_links
        
        # æŸ¥æ‰¾ç£åŠ›éˆæ¥é …ç›®
        magnet_items = []
        
        # å˜—è©¦ä¸åŒçš„é …ç›®é¸æ“‡å™¨
        item_selectors = [
            'div.magnet-item',
            'div.link-item', 
            'tr',
            'div[class*="item"]',
            'div[class*="link"]'
        ]
        
        for selector in item_selectors:
            items = magnet_section.select(selector)
            if items:
                magnet_items = items
                self.logger.info(f"ä½¿ç”¨é¸æ“‡å™¨ {selector} æ‰¾åˆ° {len(items)} å€‹é …ç›®")
                break
        
        if not magnet_items:
            # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼ŒæŸ¥æ‰¾æ‰€æœ‰åŒ…å«"è¤‡è£½"æˆ–"ä¸‹è¼‰"æŒ‰éˆ•çš„div
            magnet_items = magnet_section.find_all('div', string=lambda text: text and ('è¤‡è£½' in text or 'ä¸‹è¼‰' in text))
            if not magnet_items:
                magnet_items = magnet_section.find_all('div')
        
        self.logger.info(f"é–‹å§‹è§£æ {len(magnet_items)} å€‹ç£åŠ›éˆæ¥é …ç›®")
        
        for i, item in enumerate(magnet_items):
            try:
                magnet_link = self._parse_magnet_item(item)
                if magnet_link:
                    magnet_links.append(magnet_link)
                    self.logger.info(f"æˆåŠŸè§£æç¬¬ {i+1} å€‹ç£åŠ›éˆæ¥: {magnet_link.title}")
                else:
                    self.logger.debug(f"ç¬¬ {i+1} å€‹é …ç›®è§£æå¤±æ•—")
            except Exception as e:
                self.logger.warning(f"è§£æç£åŠ›éˆæ¥é …ç›®å¤±æ•—: {e}")
                continue
        
        self.logger.info(f"ç¸½å…±è§£æå‡º {len(magnet_links)} å€‹ç£åŠ›éˆæ¥")
        if not magnet_links:
            for ind in error_indicators:
                if ind.lower() in page_text_lower:
                    self.logger.warning(f"é é¢å¯èƒ½åŒ…å«éŒ¯èª¤æç¤ºï¼ˆ{ind}ï¼‰ï¼Œç¶²ç«™å¯èƒ½é™åˆ¶äº†è¨ªå•")
                    break
        return magnet_links
    
    def _parse_magnet_item(self, item) -> Optional[MagnetLink]:
        """è§£æç£åŠ›éˆæ¥é …ç›®"""
        magnet = MagnetLink()
        
        # ç²å–è¤‡è£½æŒ‰éˆ•çš„éˆæ¥ - é€™æ˜¯é‡é»ï¼å„ªå…ˆç²å–
        copy_button = item.find('a', class_='copy-btn') or item.find('button', class_='copy') or item.find('a', string='è¤‡è£½') or item.find('a', class_='copy')
        if copy_button:
            magnet.copy_url = copy_button.get('href', '') or copy_button.get('data-url', '') or copy_button.get('data-clipboard-text', '') or copy_button.get('data-clipboard', '')
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°è¤‡è£½æŒ‰éˆ•ï¼Œå˜—è©¦å¾å…¶ä»–å…ƒç´ ç²å–ç£åŠ›éˆæ¥
        if not magnet.copy_url:
            # æŸ¥æ‰¾åŒ…å«ç£åŠ›éˆæ¥çš„å…ƒç´ 
            magnet_link_elem = item.find('a', href=lambda x: x and x.startswith('magnet:'))
            if magnet_link_elem:
                magnet.magnet_url = magnet_link_elem.get('href', '')
                magnet.copy_url = magnet.magnet_url
        
        # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦å¾æ–‡æœ¬å…§å®¹ä¸­æå–ç£åŠ›éˆæ¥
        if not magnet.copy_url:
            item_text = item.get_text()
            # æ”¹é€²æ­£å‰‡è¡¨é”å¼ä»¥åŒ¹é…å®Œæ•´çš„ç£åŠ›éˆæ¥ï¼ˆåŒ…æ‹¬æ‰€æœ‰åƒæ•¸ï¼‰
            magnet_match = re.search(r'magnet:\?xt=urn:btih:[a-zA-Z0-9]+[^"\s<>]*', item_text)
            if magnet_match:
                magnet.copy_url = magnet_match.group(0)
                magnet.magnet_url = magnet.copy_url
        
        # å¾ç£åŠ›éˆæ¥ä¸­æå–æ¨™é¡Œï¼ˆå¾ dn åƒæ•¸ï¼‰- å„ªå…ˆæå–æ¨™é¡Œ
        if magnet.copy_url:
            # ä½¿ç”¨æ›´å¯¬é¬†çš„æ­£å‰‡è¡¨é”å¼ä¾†åŒ¹é… dn åƒæ•¸ï¼ˆå¯èƒ½åŒ…å« URL ç·¨ç¢¼çš„ç‰¹æ®Šå­—ç¬¦ï¼‰
            dn_match = re.search(r'dn=([^&]+)', magnet.copy_url, re.IGNORECASE)
            if not dn_match:
                # å¦‚æœç¬¬ä¸€å€‹æ­£å‰‡æ²’åŒ¹é…åˆ°ï¼Œå˜—è©¦åŒ¹é…åŒ…å«æ›´å¤šå­—ç¬¦çš„ç‰ˆæœ¬
                dn_match = re.search(r'dn=([^&"\s<>]+)', magnet.copy_url, re.IGNORECASE)
            if dn_match:
                dn_value = dn_match.group(1)
                # URL è§£ç¢¼
                from urllib.parse import unquote
                try:
                    decoded_dn = unquote(dn_value)
                    # æå–ç•ªè™Ÿï¼ˆä¾‹å¦‚ï¼š[javdb.com]JUR-496-C.torrent -> JUR-496-Cï¼‰
                    code_match = re.search(r'\[javdb\.com\]([A-Z0-9\-]+)', decoded_dn, re.IGNORECASE)
                    if code_match:
                        magnet.title = code_match.group(1)
                    else:
                        # å¦‚æœæ²’æœ‰ [javdb.com] å‰ç¶´ï¼Œç›´æ¥ä½¿ç”¨è§£ç¢¼å¾Œçš„å€¼ï¼ˆå»æ‰ .torrent ç­‰å¾Œç¶´ï¼‰
                        magnet.title = decoded_dn.replace('.torrent', '').replace('.mkv', '').replace('.mp4', '')
                except Exception as e:
                    magnet.title = dn_value.replace('.torrent', '').replace('.mkv', '').replace('.mp4', '')
        
        # ç²å–æ¨™é¡Œï¼ˆé€šå¸¸æ˜¯ç•ªè™Ÿï¼‰- å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        if not magnet.title:
            title_elem = (item.find('span', class_='title') or 
                         item.find('td', class_='title') or 
                         item.find('strong') or
                         item.find('div', class_='title') or
                         item.find('p', class_='title') or
                         item.find('a', class_='title'))
            if title_elem:
                magnet.title = clean_text(title_elem.get_text())
        
        # ç²å–å¤§å°å’Œæ–‡ä»¶æ•¸é‡ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        size_elem = (item.find('span', class_='size') or 
                    item.find('td', class_='size') or
                    item.find('div', class_='size') or
                    item.find('span', class_='file-size') or
                    item.find('td', string=re.compile(r'\d+\.?\d*\s*(GB|MB|KB|TB)', re.IGNORECASE)))
        if size_elem:
            size_text = clean_text(size_elem.get_text())
            magnet.size = size_text
            
            # è§£ææ–‡ä»¶æ•¸é‡
            file_count_match = re.search(r'(\d+)å€‹æ–‡ä»¶', size_text)
            if file_count_match:
                magnet.file_count = int(file_count_match.group(1))
        
        # å¦‚æœå¤§å°ä»ç„¶ç‚ºç©ºï¼Œå˜—è©¦å¾æ–‡æœ¬ä¸­æå–
        if not magnet.size:
            item_text = item.get_text()
            size_match = re.search(r'(\d+\.?\d*)\s*(GB|MB|KB|TB)', item_text, re.IGNORECASE)
            if size_match:
                magnet.size = f"{size_match.group(1)} {size_match.group(2).upper()}"
        
        # ç²å–æ¨™ç±¤ï¼ˆé«˜æ¸…ã€å­—å¹•ç­‰ï¼‰- å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        tag_elems = (item.find_all('span', class_='tag') or 
                    item.find_all('span', class_='label') or 
                    item.find_all('span', class_='badge') or
                    item.find_all('div', class_='tag') or
                    item.find_all('a', class_='tag'))
        for tag_elem in tag_elems:
            tag_text = clean_text(tag_elem.get_text())
            if tag_text in ['é«˜æ¸…', 'å­—å¹•', 'HD', 'Subtitle', '4K', '1080p', '720p', 'ä¸­æ–‡', 'Chinese']:
                if tag_text not in magnet.tags:
                    magnet.tags.append(tag_text)
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™ç±¤å…ƒç´ ï¼Œå˜—è©¦å¾æ–‡æœ¬ä¸­è­˜åˆ¥
        if not magnet.tags:
            item_text = item.get_text()
            if any(keyword in item_text for keyword in ['é«˜æ¸…', 'HD', '4K', '1080p', '720p']):
                magnet.tags.append('é«˜æ¸…')
            if any(keyword in item_text for keyword in ['å­—å¹•', 'Subtitle', 'ä¸­æ–‡', 'Chinese']):
                magnet.tags.append('å­—å¹•')
        
        # ç²å–ä¸‹è¼‰æŒ‰éˆ•çš„éˆæ¥
        download_button = item.find('a', class_='download-btn') or item.find('button', class_='download') or item.find('a', string='ä¸‹è¼‰')
        if download_button:
            magnet.download_url = download_button.get('href', '') or download_button.get('data-url', '')
        
        # ç²å–æ—¥æœŸ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        date_elem = (item.find('span', class_='date') or 
                    item.find('td', class_='date') or
                    item.find('div', class_='date') or
                    item.find('time') or
                    item.find('span', class_='time'))
        if date_elem:
            magnet.date = clean_text(date_elem.get_text())
        
        # è§£ææ–‡ä»¶æ•¸é‡ï¼ˆå¦‚æœé‚„æ²’è§£æåˆ°ï¼‰
        if magnet.file_count == 0:
            item_text = item.get_text()
            file_count_match = re.search(r'(\d+)å€‹æ–‡ä»¶', item_text)
            if file_count_match:
                magnet.file_count = int(file_count_match.group(1))
        
        # èª¿è©¦ä¿¡æ¯
        self.logger.info(f"è§£æç£åŠ›éˆæ¥é …ç›®: æ¨™é¡Œ={magnet.title}, å¤§å°={magnet.size}, æ¨™ç±¤={magnet.tags}, è¤‡è£½éˆæ¥={magnet.copy_url}")
        
        return magnet if magnet.copy_url or magnet.magnet_url else None
    
    def _extract_real_code_from_magnet(self, magnet_url: str) -> str:
        """å¾ç£åŠ›éˆæ¥URLä¸­æå–çœŸå¯¦ç•ªè™Ÿ"""
        if not magnet_url:
            return ""
        
        # å¾ç£åŠ›éˆæ¥URLä¸­æå–ç•ªè™Ÿï¼ˆæ ¼å¼ï¼š[javdb.com]ONSG-098ï¼‰
        code_match = re.search(r'\[javdb\.com\]([A-Z0-9\-]+)', magnet_url)
        if code_match:
            return code_match.group(1)
        
        return ""
    
    def _filter_magnets_by_priority(self, magnet_links: List[MagnetLink]) -> List[MagnetLink]:
        """æ ¹æ“šå„ªå…ˆé †åºé¸æ“‡ä¸€å€‹æœ€ä½³ç£åŠ›éˆæ¥"""
        if not magnet_links:
            return []
        
        # å„ªå…ˆé †åºï¼š1.é«˜æ¸… 2.å­—å¹• 3.ç¬¬ä¸€å€‹
        high_quality = []
        subtitle = []
        
        for magnet in magnet_links:
            has_high_quality = any(tag in magnet.tags for tag in ['é«˜æ¸…', 'HD', '4K', '1080p', '720p'])
            has_subtitle = any(tag in magnet.tags for tag in ['å­—å¹•', 'Subtitle'])
            
            if has_high_quality:
                high_quality.append(magnet)
            elif has_subtitle:
                subtitle.append(magnet)
        
        # æŒ‰å„ªå…ˆé †åºè¿”å›ä¸€å€‹æœ€ä½³é¸æ“‡
        if high_quality:
            self.logger.info(f"é¸æ“‡é«˜æ¸…ç£åŠ›éˆæ¥: {high_quality[0].copy_url}")
            return [high_quality[0]]  # åªè¿”å›ç¬¬ä¸€å€‹é«˜æ¸…
        elif subtitle:
            self.logger.info(f"é¸æ“‡å­—å¹•ç£åŠ›éˆæ¥: {subtitle[0].copy_url}")
            return [subtitle[0]]  # åªè¿”å›ç¬¬ä¸€å€‹å­—å¹•
        else:
            self.logger.info(f"é¸æ“‡ç¬¬ä¸€å€‹ç£åŠ›éˆæ¥: {magnet_links[0].copy_url}")
            return [magnet_links[0]]  # åªè¿”å›ç¬¬ä¸€å€‹
    
    def get_magnet_download_url(self, magnet_link: MagnetLink) -> Optional[str]:
        """ç²å–ç£åŠ›éˆæ¥çš„å¯¦éš›ä¸‹è¼‰URL"""
        if magnet_link.copy_url:
            # å¦‚æœè¤‡è£½æŒ‰éˆ•æœ‰ç›´æ¥çš„URL
            if magnet_link.copy_url.startswith('magnet:'):
                return magnet_link.copy_url
            
            # å¦‚æœæ˜¯ç›¸å°URLï¼Œè½‰æ›ç‚ºçµ•å°URL
            if not magnet_link.copy_url.startswith('http'):
                return urljoin(self.base_url, magnet_link.copy_url)
            
            return magnet_link.copy_url
        
        return magnet_link.magnet_url

class JavDBMagnetManager:
    """JavDB ç£åŠ›éˆæ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.crawler = JavDBMagnetCrawler()
        self.logger = setup_logging()
        self.tracker = DuplicateTracker()
        self.written_urls = set()  # ç”¨æ–¼è·Ÿè¸ªå·²å¯«å…¥çš„URLï¼Œé¿å…é‡è¤‡
    
    def get_top30_magnets(self, skip_duplicates: bool = True, rank_type: str = "monthly", limit: int = None) -> List[Dict[str, Any]]:
        """ç²å–æœ‰ç¢¼æ’è¡Œæ¦œå‰Nçš„ç£åŠ›éˆæ¥
        
        Args:
            skip_duplicates: æ˜¯å¦è·³éå·²çˆ¬å–çš„å½±ç‰‡
            rank_type: æ’è¡Œæ¦œé¡å‹ ("monthly" æœˆæ¦œ)
            limit: ä¸‹è¼‰æ•¸é‡ï¼ˆå¦‚æœç‚ºNoneï¼Œå‰‡å¾é…ç½®æ–‡ä»¶è®€å–ï¼‰
        """
        # åªæ”¯æŒæœˆæ¦œ
        if rank_type != "monthly":
            rank_type = "monthly"
            self.logger.warning("å·²å°‡æ’è¡Œæ¦œé¡å‹æ”¹ç‚ºæœˆæ¦œï¼ˆmonthlyï¼‰")
        
        # å¾ç’°å¢ƒè®Šæ•¸è®€å– limitï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if limit is None:
            import os
            from dotenv import load_dotenv
            load_dotenv('config.env')
            top_count_raw = os.getenv('TOP_COUNT', '30')
            limit = int(top_count_raw)
        
        return self.get_top30_monthly_with_duplicate_check(limit=limit) if skip_duplicates else self.crawler.get_monthly_rankings_with_magnets(limit)
    
    def get_top30_monthly_with_duplicate_check(self, limit: int = 30) -> List[Dict[str, Any]]:
        """ç²å–å‰Næœˆæ¦œï¼Œè·³éå·²çˆ¬å–çš„å½±ç‰‡ï¼ˆå…±äº«é‡è¤‡æª¢æ¸¬ï¼‰"""
        # æª¢æŸ¥çµ±è¨ˆä¿¡æ¯
        stats = self.tracker.get_statistics()
        if stats['total_scraped'] > 0:
            self.logger.info(f"ğŸ“Š å·²è¨˜éŒ„ {stats['total_scraped']} éƒ¨å½±ç‰‡ï¼Œå°‡è‡ªå‹•è·³éé‡è¤‡")
        else:
            # å¦‚æœ scraped_movies.json ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œæ¸…ç©º written_urls ä»¥ç¢ºä¿ä¸€è‡´æ€§
            # é€™æ¨£å¯ä»¥é¿å…å› ç‚ºèˆŠçš„ url_list_monthly.txt å°è‡´èª¤åˆ¤é‡è¤‡
            self.written_urls.clear()
            self.logger.info("ğŸ“‹ æª¢æ¸¬åˆ°ç„¡æ­·å²è¨˜éŒ„ï¼Œå·²æ¸…ç©ºURLé‡è¤‡æª¢æŸ¥åˆ—è¡¨")
        
        self.logger.info(f"é–‹å§‹ç²å–æœ‰ç¢¼æœˆæ¦œå‰{limit}çš„å½±ç‰‡ç£åŠ›éˆæ¥ï¼ˆæª¢æŸ¥é‡è¤‡ï¼‰")
        
        # ç›´æ¥è«‹æ±‚æ’è¡Œæ¦œï¼ˆå·²å¸¶ over18=1 cookie èˆ‡ Chrome TLSï¼‰
        self.crawler.session.headers['User-Agent'] = FIXED_CHROME_UA
        # 1. ç²å–æ’è¡Œæ¦œé é¢
        rankings_url = f"{self.crawler.base_url}/rankings/movies"
        params = {
            "p": "monthly",  # æœˆæ¦œ
            "t": "censored",  # æœ‰ç¢¼
            "page": 1
        }
        response = self.crawler._make_request(
            rankings_url, params,
            skip_ua_rotation=True,
            extra_headers={"Referer": self.crawler.base_url + "/"}
        )
        if not response:
            self.logger.error("ç„¡æ³•ç²å–æ’è¡Œæ¦œé é¢")
            return []
        
        # 2. è§£ææ’è¡Œæ¦œï¼Œç²å–å½±ç‰‡åˆ—è¡¨
        all_movies = self.crawler._parse_rankings_page(response.text, limit)
        self.logger.info(f"å¾æœˆæ¦œæ’è¡Œæ¦œç²å–åˆ° {len(all_movies)} éƒ¨å½±ç‰‡")
        
        # 3. éæ¿¾å‡ºæœªçˆ¬å–çš„å½±ç‰‡
        new_movies, skipped_count = self.tracker.get_new_movies(all_movies)
        self.logger.info(f"âœ“ è·³é {skipped_count} éƒ¨å·²çˆ¬å–çš„å½±ç‰‡")
        self.logger.info(f"âœ“ å‰©é¤˜ {len(new_movies)} éƒ¨æ–°å½±ç‰‡")
        if not new_movies:
            self.logger.info("æ²’æœ‰æ–°å½±ç‰‡éœ€è¦çˆ¬å–")
            return []
        
        # 4. ä½¿ç”¨å›ºå®šæª”åï¼ˆæœˆæ¦œå°ˆç”¨ï¼‰ï¼Œå§‹çµ‚è¿½åŠ æ¨¡å¼
        os.makedirs("magnet", exist_ok=True)
        filename = "magnet/url_list_monthly.txt"
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡éœ€è¦åˆå§‹åŒ– written_urls
        # æ³¨æ„ï¼šå¦‚æœ scraped_movies.json ä¸å­˜åœ¨ï¼ˆå·²åœ¨ä¸Šæ–¹æ¸…ç©º written_urlsï¼‰ï¼Œ
        # é€™è£¡ä¸å†å¾ url_list_monthly.txt è®€å– URLï¼Œç¢ºä¿ä¸€è‡´æ€§
        if not os.path.exists(filename):
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ¸…ç©º written_urlsï¼ˆæ–°æ–‡ä»¶ï¼‰
            self.written_urls.clear()
            self.logger.info(f"å‰µå»ºæ–°æ–‡ä»¶: {filename}")
        else:
            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½†åªæœ‰åœ¨ scraped_movies.json ä¹Ÿå­˜åœ¨æ™‚æ‰è®€å–ç¾æœ‰URL
            # é€™æ¨£å¯ä»¥é¿å…å› ç‚ºåªæœ‰ url_list_monthly.txt è€Œèª¤åˆ¤é‡è¤‡
            scraped_movies_exists = os.path.exists(self.tracker.db_file)
            if scraped_movies_exists:
                # æ–‡ä»¶å·²å­˜åœ¨ï¼Œè®€å–ç¾æœ‰URLåˆ° written_urls ä¸­ï¼ˆé¿å…é‡è¤‡ï¼‰
                try:
                    with open(filename, 'r', encoding='utf-8') as f:
                        existing_urls = [line.strip() for line in f if line.strip() and not line.strip().startswith('20')]  # éæ¿¾æ‰æ—¥æœŸæ¨™é¡Œè¡Œ
                        self.written_urls.update(existing_urls)
                    self.logger.info(f"è¿½åŠ åˆ°ç¾æœ‰æ–‡ä»¶: {filename} (å·²æœ‰ {len(self.written_urls)} å€‹URL)")
                except Exception as e:
                    self.logger.warning(f"è®€å–ç¾æœ‰æ–‡ä»¶å¤±æ•—: {e}ï¼Œå°‡ç¹¼çºŒè¿½åŠ ")
            else:
                # scraped_movies.json ä¸å­˜åœ¨ï¼Œä¸æ¸…é™¤ written_urlsï¼ˆå·²åœ¨ä¸Šé¢æ¸…ç©ºï¼‰
                # ä½†ä¹Ÿä¸å¾ url_list_monthly.txt è®€å–ï¼Œç¢ºä¿ä¸€è‡´æ€§
                self.logger.info(f"æª¢æ¸¬åˆ° {filename} å­˜åœ¨ä½† scraped_movies.json ä¸å­˜åœ¨ï¼Œå¿½ç•¥æœˆæ¦œæª”ä¸­çš„èˆŠURLä»¥ç¢ºä¿ä¸€è‡´æ€§")
        
        file_mode = 'a'  # å§‹çµ‚ä½¿ç”¨è¿½åŠ æ¨¡å¼
        
        # æª¢æŸ¥æ–‡ä»¶æœ€å¾Œä¸€è¡Œæ˜¯å¦ç‚ºä»Šå¤©çš„æ—¥æœŸæ¨™é¡Œ
        current_date = datetime.now().strftime('%Y/%m/%d')
        needs_date_header = True
        if os.path.exists(filename) and os.path.getsize(filename) > 0:
            try:
                with open(filename, 'r', encoding='utf-8') as check_file:
                    lines = check_file.readlines()
                    if lines:
                        # å¾å¾Œå¾€å‰æ‰¾æœ€å¾Œä¸€å€‹éç©ºè¡Œ
                        for line in reversed(lines):
                            last_line = line.strip()
                            if last_line:
                                # æª¢æŸ¥æ˜¯å¦ç‚ºä»Šå¤©çš„æ—¥æœŸæ ¼å¼ YYYY/MM/DD
                                if last_line == current_date:
                                    needs_date_header = False
                                break
            except Exception:
                pass
        
        # 5. ç‚ºæ¯éƒ¨æ–°å½±ç‰‡ç²å–ç£åŠ›éˆæ¥ä¸¦å³æ™‚å¯«å…¥
        results = []
        scraped_codes = []  # è¨˜éŒ„æˆåŠŸçˆ¬å–çš„ç•ªè™Ÿ
        
        with open(filename, file_mode, encoding='utf-8') as f:
            # å¦‚æœéœ€è¦ï¼Œå¯«å…¥æ—¥æœŸæ¨™é¡Œ
            if needs_date_header:
                f.write(f"\n{current_date}\n")
            
            for i, movie in enumerate(new_movies, 1):
                self.logger.info(f"è™•ç†ç¬¬ {i}/{len(new_movies)} éƒ¨æ–°å½±ç‰‡: {movie['title']}")
                
                # ç²å–ç£åŠ›éˆæ¥
                magnet_links = self.crawler.get_movie_magnet_links(movie['detail_url'])
                
                # æ ¹æ“šå„ªå…ˆé †åºéæ¿¾ç£åŠ›éˆæ¥
                filtered_magnets = self.crawler._filter_magnets_by_priority(magnet_links)
                
                # å˜—è©¦å¾ç£åŠ›éˆæ¥ä¸­æå–çœŸå¯¦ç•ªè™Ÿ
                real_code = None
                if filtered_magnets:
                    magnet = filtered_magnets[0]
                    real_code = self.crawler._extract_real_code_from_magnet(magnet.copy_url or magnet.magnet_url)
                    if real_code:
                        movie['code'] = real_code  # æ›´æ–°ç‚ºçœŸå¯¦ç•ªè™Ÿ
                    elif not movie.get('code') or len(movie.get('code', '')) < 5:
                        # å¦‚æœæ²’æœ‰æå–åˆ°çœŸå¯¦ç•ªè™Ÿï¼Œå˜—è©¦å¾æ¨™é¡Œæå–
                        title = movie.get('title', '')
                        code_match = re.search(r'([A-Z]{2,6}-\d{3,5})', title)
                        if code_match:
                            extracted_code = code_match.group(1)
                            movie['code'] = extracted_code
                            real_code = extracted_code
                
                result = {
                    'rank': i,
                    'movie': movie,
                    'magnet_links': filtered_magnets,
                    'total_magnets': len(magnet_links),
                    'filtered_magnets': len(filtered_magnets)
                }
                
                results.append(result)
                
                # ä½¿ç”¨çœŸå¯¦ç•ªè™Ÿè¨˜éŒ„ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦å‰‡ä½¿ç”¨åŸå§‹ code
                code_to_record = real_code or movie.get('code', '')
                
                # å³æ™‚å¯«å…¥åˆ°æ–‡ä»¶ï¼ˆåªä¿å­˜URLï¼Œæª¢æŸ¥é‡è¤‡ï¼‰
                if filtered_magnets:
                    magnet = filtered_magnets[0]  # åªå–ç¬¬ä¸€å€‹ï¼ˆæœ€ä½³é¸æ“‡ï¼‰
                    url = magnet.copy_url or magnet.magnet_url
                    # æ¨™æº–åŒ–URLï¼ˆå»é™¤é¦–å°¾ç©ºæ ¼ï¼‰
                    if url:
                        url = url.strip()
                    # æª¢æŸ¥URLæ˜¯å¦å·²ç¶“å¯«å…¥éï¼ˆé¿å…é‡è¤‡ï¼‰
                    if url and url not in self.written_urls:
                        f.write(f"{url}\n")
                        self.written_urls.add(url)  # è¨˜éŒ„å·²å¯«å…¥çš„URL
                    elif url and url in self.written_urls:
                        self.logger.info(f"è·³éé‡è¤‡URL: {url}")
                
                # ç„¡è«–æ˜¯å¦æœ‰ç£åŠ›éˆæ¥ï¼Œåªè¦æœ‰æœ‰æ•ˆçš„ç•ªè™Ÿå°±è¨˜éŒ„ç‚ºå·²è™•ç†ï¼ˆé¿å…é‡è¤‡çˆ¬å–ï¼‰
                # é©—è­‰ç•ªè™Ÿæ ¼å¼ï¼Œåªè¨˜éŒ„æœ‰æ•ˆçš„ç•ªè™Ÿï¼Œä¸¦ç«‹å³å¯«å…¥åˆ° scraped_movies.json
                if code_to_record and self.tracker._is_valid_code(code_to_record):
                    self.tracker.mark_and_save(code_to_record)  # å³æ™‚å¯«å…¥
                    scraped_codes.append(code_to_record)  # ä¿ç•™ç”¨æ–¼çµ±è¨ˆ
                    if not filtered_magnets:
                        self.logger.info(f"å½±ç‰‡ {code_to_record} æ²’æœ‰æ‰¾åˆ°ç£åŠ›éˆæ¥ï¼Œä½†å·²è¨˜éŒ„ç‚ºå·²è™•ç†")
                else:
                    # å¦‚æœç•ªè™Ÿæ ¼å¼ç•°å¸¸ï¼Œè¨˜éŒ„è­¦å‘Šä½†ç¹¼çºŒè™•ç†
                    if code_to_record:
                        self.logger.warning(f"è·³éè¨˜éŒ„ç•°å¸¸æ ¼å¼çš„ç•ªè™Ÿ: {code_to_record} (æ¨™é¡Œ: {movie.get('title', '')})")
                
                f.flush()  # å¼·åˆ¶å¯«å…¥ï¼Œç¢ºä¿å³æ™‚ä¿å­˜
                
                # é¿å…è«‹æ±‚éæ–¼é »ç¹ - å¢åŠ å»¶é²æ™‚é–“ä»¥é™ä½è¢«å°é–çš„é¢¨éšªï¼ˆä½¿ç”¨æ¨¡çµ„é ‚å±¤å°å…¥çš„ random_delayï¼‰
                if not filtered_magnets:
                    self.logger.warning(f"å½±ç‰‡ {movie.get('title', '')} æœªæ‰¾åˆ°ç£åŠ›éˆæ¥ï¼Œå»¶é²æ›´é•·æ™‚é–“...")
                    random_delay(5, 8)  # å»¶é•·åˆ°5-8ç§’
                else:
                    random_delay(3, 6)  # æ­£å¸¸æƒ…æ³å»¶é²3-6ç§’ï¼ˆå¾2-4ç§’å¢åŠ ï¼‰
        
        self.logger.info(f"ç£åŠ›éˆæ¥å·²å³æ™‚ä¿å­˜åˆ°: {filename}")
        
        # 6. å·²çˆ¬å–çš„å½±ç‰‡å·²é€šé mark_and_save å³æ™‚å¯«å…¥ï¼Œé€™è£¡åªè¨˜éŒ„çµ±è¨ˆä¿¡æ¯
        if scraped_codes:
            self.logger.info(f"å·²æ¨™è¨˜ {len(scraped_codes)} éƒ¨å½±ç‰‡ç‚ºå·²çˆ¬å–ï¼ˆå·²å³æ™‚ä¿å­˜åˆ° scraped_movies.jsonï¼‰")
        
        return results
    
    def get_magnets_by_code(self, movie_code: str) -> List[MagnetLink]:
        """æ ¹æ“šç•ªè™Ÿç²å–ç£åŠ›éˆæ¥"""
        # å…ˆé€šéæœç´¢æ‰¾åˆ°æ­£ç¢ºçš„å½±ç‰‡ URLï¼ˆåŒ…å«æ­£ç¢ºçš„ IDï¼‰
        movie_url = self.crawler.search_movie_by_code(movie_code)
        
        if not movie_url:
            self.logger.error(f"ç„¡æ³•æ‰¾åˆ°ç•ªè™Ÿ {movie_code} çš„å½±ç‰‡")
            return []
        
        return self.crawler.get_movie_magnet_links(movie_url)
    
    def export_magnets_to_file(self, results: List[Dict[str, Any]], 
                              filename: str = None) -> str:
        """å°å‡ºç£åŠ›éˆæ¥åˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"magnet/javdb_magnets_{timestamp}.txt"
        
        # ç¢ºä¿ magnet è³‡æ–™å¤¾å­˜åœ¨
        os.makedirs("magnet", exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("JavDB æœ‰ç¢¼æœˆæ¦œå‰30ç£åŠ›éˆæ¥\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n\n")
            
            # çµ±è¨ˆä¿¡æ¯
            total_movies = len(results)
            total_magnets = sum(result['total_magnets'] for result in results)
            filtered_magnets = sum(result['filtered_magnets'] for result in results)
            
            f.write(f"çµ±è¨ˆä¿¡æ¯:\n")
            f.write(f"ç¸½å½±ç‰‡æ•¸: {total_movies}\n")
            f.write(f"ç¸½ç£åŠ›éˆæ¥æ•¸: {total_magnets}\n")
            f.write(f"éæ¿¾å¾Œç£åŠ›éˆæ¥æ•¸: {filtered_magnets}\n")
            f.write(f"æˆåŠŸç‡: {filtered_magnets/total_magnets*100:.1f}%\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("ç£åŠ›éˆæ¥åˆ—è¡¨\n")
            f.write("=" * 80 + "\n\n")
            
            for result in results:
                movie = result['movie']
                f.write(f"æ’å: {result['rank']}\n")
                f.write(f"ç•ªè™Ÿ: {movie['code']}\n")
                f.write(f"æ¨™é¡Œ: {movie['title']}\n")
                f.write(f"æ¼”å“¡: {', '.join(movie['actors'])}\n")
                f.write(f"è©•åˆ†: {movie['score']}\n")
                f.write(f"ç¸½ç£åŠ›éˆæ¥: {result['total_magnets']} å€‹\n")
                f.write(f"éæ¿¾å¾Œç£åŠ›éˆæ¥: {result['filtered_magnets']} å€‹\n")
                
                if result['magnet_links']:
                    f.write("ç£åŠ›éˆæ¥:\n")
                    for i, magnet in enumerate(result['magnet_links'], 1):
                        f.write(f"  {i}. {magnet.title}\n")
                        f.write(f"     å¤§å°: {magnet.size}\n")
                        f.write(f"     æ¨™ç±¤: {', '.join(magnet.tags)}\n")
                        f.write(f"     ä¸‹è¼‰éˆæ¥: {magnet.copy_url or magnet.magnet_url}\n")
                        f.write(f"     æ—¥æœŸ: {magnet.date}\n")
                        f.write("\n")
                else:
                    f.write("ç„¡ç¬¦åˆæ¢ä»¶çš„ç£åŠ›éˆæ¥\n")
                
                f.write("-" * 80 + "\n\n")
            
            # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ç´”ç£åŠ›éˆæ¥åˆ—è¡¨
            f.write("=" * 80 + "\n")
            f.write("ç´”ç£åŠ›éˆæ¥åˆ—è¡¨ï¼ˆæ–¹ä¾¿è¤‡è£½ï¼‰\n")
            f.write("=" * 80 + "\n\n")
            
            magnet_count = 0
            for result in results:
                if result['magnet_links']:
                    for magnet in result['magnet_links']:
                        magnet_count += 1
                        f.write(f"{magnet_count}. {magnet.copy_url or magnet.magnet_url}\n")
            
            f.write(f"\nç¸½å…± {magnet_count} å€‹ç£åŠ›éˆæ¥\n")
        
        self.logger.info(f"ç£åŠ›éˆæ¥å·²å°å‡ºåˆ°: {filename}")
        return filename
    
    def get_summary_stats(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆæ‘˜è¦"""
        total_movies = len(results)
        total_magnets = sum(result['total_magnets'] for result in results)
        filtered_magnets = sum(result['filtered_magnets'] for result in results)
        
        movies_with_magnets = sum(1 for result in results if result['filtered_magnets'] > 0)
        
        return {
            'total_movies': total_movies,
            'total_magnets': total_magnets,
            'filtered_magnets': filtered_magnets,
            'movies_with_magnets': movies_with_magnets,
            'success_rate': movies_with_magnets / total_movies if total_movies > 0 else 0
        }

